#include <iostream>
#include <cuda_runtime.h>
#include <chrono>
#include <iomanip>
#include <vector>
#include <string>
using namespace std;
using namespace chrono;
extern "C" void im2col_gpu(const float* data_im, float* data_col, int batch_size, int channels, int height, int width, int ksize, int pad, int stride, int h_out, int w_out);
extern "C" __global__ void gemm_tiled(const float* A, const float* B, float* C, int M, int N, int K);
extern "C" __global__ void relu(float *x, int size);
extern "C" __global__ void maxpool(const float *input, float *output, int H, int W, int C);
extern "C" __global__ void upsample(const float *input, float *output, int H, int W, int C);
void conv2d_backward_weights_gemm_optimized(const float* grad_output, const float* input, float* grad_weights, float* col_buffer, int H_in, int W_in, int C_in, int H_out, int W_out, int C_out, int ksize, int pad, int stride);
void conv2d_backward_input_gemm_optimized(const float* grad_output, const float* weights, float* grad_input, float* col_buffer, int H_in, int W_in, int C_in, int H_out, int W_out, int C_out, int ksize, int pad, int stride);
extern "C" __global__ void relu_backward(const float* grad_output, const float* input_before_relu, float* grad_input, int N);
extern "C" __global__ void upsample_backward(const float* grad_output, float* grad_input, int H_in, int W_in, int C);
void* gpu_malloc(size_t size) { void* ptr; cudaMalloc(&ptr, size); return ptr; }
void forward_conv_gemm(const float* d_input, const float* d_weights, float* d_output, float* d_col_buffer,
                       int H, int W, int C_in, int C_out) {
    int ksize = 3, pad = 1, stride = 1;
    int H_out = H, W_out = W;
    im2col_gpu(d_input, d_col_buffer, 1, C_in, H, W, ksize, pad, stride, H_out, W_out);
    int M = C_out, N = H_out * W_out, K = C_in * ksize * ksize;
    dim3 dimGrid((N + 15)/16, (M + 15)/16);
    dim3 dimBlock(16, 16);
    gemm_tiled<<<dimGrid, dimBlock>>>(d_weights, d_col_buffer, d_output, M, N, K);
}
int main() {
    cout << "============================================" << endl;
    cout << " P3_2 Timing Benchmark (Optimized GEMM)" << endl;
    cout << "============================================" << endl << endl;
    const int H = 32, W = 32, C = 3;
    dim3 block(16, 16);
    float *d_input = (float*)gpu_malloc(C * H * W * sizeof(float));
    float *d_conv1_out = (float*)gpu_malloc(256 * H * W * sizeof(float));
    float *d_pool1_out = (float*)gpu_malloc(256 * (H/2) * (W/2) * sizeof(float));
    float *d_conv2_out = (float*)gpu_malloc(128 * (H/2) * (W/2) * sizeof(float));
    float *d_pool2_out = (float*)gpu_malloc(128 * (H/4) * (W/4) * sizeof(float));
    float *d_dec1_out = (float*)gpu_malloc(128 * (H/4) * (W/4) * sizeof(float));
    float *d_ups1_out = (float*)gpu_malloc(128 * (H/2) * (W/2) * sizeof(float));
    float *d_dec2_out = (float*)gpu_malloc(256 * (H/2) * (W/2) * sizeof(float));
    float *d_ups2_out = (float*)gpu_malloc(256 * H * W * sizeof(float));
    float *d_output = (float*)gpu_malloc(C * H * W * sizeof(float));
    size_t max_col_size = 256 * 9 * 32 * 32 * sizeof(float);
    float *d_col_buffer = (float*)gpu_malloc(max_col_size);
    float *d_w_conv1 = (float*)gpu_malloc(256 * C * 3 * 3 * sizeof(float));
    float *d_w_conv2 = (float*)gpu_malloc(128 * 256 * 3 * 3 * sizeof(float));
    float *d_w_dec1 = (float*)gpu_malloc(128 * 128 * 3 * 3 * sizeof(float));
    float *d_w_dec2 = (float*)gpu_malloc(256 * 128 * 3 * 3 * sizeof(float));
    float *d_w_final = (float*)gpu_malloc(C * 256 * 3 * 3 * sizeof(float));
    float *d_grad_output = (float*)gpu_malloc(C * H * W * sizeof(float));
    float *d_grad_ups2_out = (float*)gpu_malloc(256 * H * W * sizeof(float));
    float *d_grad_dec2_out = (float*)gpu_malloc(256 * (H/2) * (W/2) * sizeof(float));
    float *d_grad_ups1_out = (float*)gpu_malloc(128 * (H/2) * (W/2) * sizeof(float));
    float *d_grad_dec1_out = (float*)gpu_malloc(128 * (H/4) * (W/4) * sizeof(float));
    float *d_grad_pool2_out = (float*)gpu_malloc(128 * (H/4) * (W/4) * sizeof(float));
    float *d_grad_conv2_out = (float*)gpu_malloc(128 * (H/2) * (W/2) * sizeof(float));
    float *d_grad_pool1_out = (float*)gpu_malloc(256 * (H/2) * (W/2) * sizeof(float));
    float *d_grad_conv1_out = (float*)gpu_malloc(256 * H * W * sizeof(float));
    cudaMemset(d_input, 1, C * H * W * sizeof(float));
    cudaMemset(d_w_conv1, 1, 256 * C * 3 * 3 * sizeof(float));
    cudaMemset(d_w_conv2, 1, 128 * 256 * 3 * 3 * sizeof(float));
    cudaMemset(d_w_dec1, 1, 128 * 128 * 3 * 3 * sizeof(float));
    cudaMemset(d_w_dec2, 1, 256 * 128 * 3 * 3 * sizeof(float));
    cudaMemset(d_w_final, 1, C * 256 * 3 * 3 * sizeof(float));
    cudaMemset(d_grad_output, 1, C * H * W * sizeof(float));
    vector<pair<string, float>> fwd_times, bwd_times;
    cout << "--- FORWARD PASS (Optimized GEMM) ---" << endl << endl;
    auto total_fwd_start = high_resolution_clock::now();
    auto start = high_resolution_clock::now();
    forward_conv_gemm(d_input, d_w_conv1, d_conv1_out, d_col_buffer, H, W, C, 256);
    cudaDeviceSynchronize();
    auto end = high_resolution_clock::now();
    fwd_times.push_back({"Conv1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    relu<<<(256*H*W+255)/256, 256>>>(d_conv1_out, 256*H*W);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"ReLU1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    maxpool<<<dim3((W/2+15)/16, (H/2+15)/16, 256), block>>>(d_conv1_out, d_pool1_out, H, W, 256);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"MaxPool1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    forward_conv_gemm(d_pool1_out, d_w_conv2, d_conv2_out, d_col_buffer, H/2, W/2, 256, 128);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"Conv2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    relu<<<(128*H/2*W/2+255)/256, 256>>>(d_conv2_out, 128*H/2*W/2);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"ReLU2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    maxpool<<<dim3((W/4+15)/16, (H/4+15)/16, 128), block>>>(d_conv2_out, d_pool2_out, H/2, W/2, 128);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"MaxPool2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    forward_conv_gemm(d_pool2_out, d_w_dec1, d_dec1_out, d_col_buffer, H/4, W/4, 128, 128);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"Dec1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    upsample<<<dim3((W/2+15)/16, (H/2+15)/16, 128), block>>>(d_dec1_out, d_ups1_out, H/4, W/4, 128);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"Upsample1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    forward_conv_gemm(d_ups1_out, d_w_dec2, d_dec2_out, d_col_buffer, H/2, W/2, 128, 256);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"Dec2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    upsample<<<dim3((W+15)/16, (H+15)/16, 256), block>>>(d_dec2_out, d_ups2_out, H/2, W/2, 256);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"Upsample2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    forward_conv_gemm(d_ups2_out, d_w_final, d_output, d_col_buffer, H, W, 256, C);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    fwd_times.push_back({"Final Conv", duration<float, milli>(end - start).count()});
    auto total_fwd_end = high_resolution_clock::now();
    float total_fwd = duration<float, milli>(total_fwd_end - total_fwd_start).count();
    for (auto& p : fwd_times) {
        cout << left << setw(12) << p.first << fixed << setprecision(3) << setw(8) << p.second << " ms  (" 
             << setprecision(1) << setw(5) << (p.second/total_fwd*100) << "%)" << endl;
    }
    cout << "\nFORWARD TOTAL: " << fixed << setprecision(3) << total_fwd << " ms" << endl;
    cout << "\n--- BACKWARD PASS (Optimized GEMM) ---" << endl << endl;
    auto total_bwd_start = high_resolution_clock::now();
    start = high_resolution_clock::now();
    conv2d_backward_weights_gemm_optimized(d_grad_output, d_ups2_out, d_w_final, d_col_buffer, H, W, 256, H, W, C, 3, 1, 1);
    conv2d_backward_input_gemm_optimized(d_grad_output, d_w_final, d_grad_ups2_out, d_col_buffer, H, W, 256, H, W, C, 3, 1, 1);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"Final Conv", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    dim3 grid_ups2_bw((W/2+15)/16, (H/2+15)/16, 256);
    upsample_backward<<<grid_ups2_bw, block>>>(d_grad_ups2_out, d_grad_dec2_out, H/2, W/2, 256);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"Upsample2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    conv2d_backward_weights_gemm_optimized(d_grad_dec2_out, d_ups1_out, d_w_dec2, d_col_buffer, H/2, W/2, 128, H/2, W/2, 256, 3, 1, 1);
    conv2d_backward_input_gemm_optimized(d_grad_dec2_out, d_w_dec2, d_grad_ups1_out, d_col_buffer, H/2, W/2, 128, H/2, W/2, 256, 3, 1, 1);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"Dec2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    dim3 grid_ups1_bw((W/4+15)/16, (H/4+15)/16, 128);
    upsample_backward<<<grid_ups1_bw, block>>>(d_grad_ups1_out, d_grad_dec1_out, H/4, W/4, 128);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"Upsample1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    conv2d_backward_weights_gemm_optimized(d_grad_dec1_out, d_pool2_out, d_w_dec1, d_col_buffer, H/4, W/4, 128, H/4, W/4, 128, 3, 1, 1);
    conv2d_backward_input_gemm_optimized(d_grad_dec1_out, d_w_dec1, d_grad_pool2_out, d_col_buffer, H/4, W/4, 128, H/4, W/4, 128, 3, 1, 1);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"Dec1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    cudaMemcpy(d_grad_conv2_out, d_grad_pool2_out, 128*(H/2)*(W/2)*sizeof(float), cudaMemcpyDeviceToDevice);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"MaxPool2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    relu_backward<<<(128*H/2*W/2+255)/256, 256>>>(d_grad_conv2_out, d_conv2_out, d_grad_conv2_out, 128*H/2*W/2);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"ReLU2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    conv2d_backward_weights_gemm_optimized(d_grad_conv2_out, d_pool1_out, d_w_conv2, d_col_buffer, H/2, W/2, 256, H/2, W/2, 128, 3, 1, 1);
    conv2d_backward_input_gemm_optimized(d_grad_conv2_out, d_w_conv2, d_grad_pool1_out, d_col_buffer, H/2, W/2, 256, H/2, W/2, 128, 3, 1, 1);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"Conv2", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    cudaMemcpy(d_grad_conv1_out, d_grad_pool1_out, 256*H*W*sizeof(float), cudaMemcpyDeviceToDevice);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"MaxPool1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    relu_backward<<<(256*H*W+255)/256, 256>>>(d_grad_conv1_out, d_conv1_out, d_grad_conv1_out, 256*H*W);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"ReLU1", duration<float, milli>(end - start).count()});
    start = high_resolution_clock::now();
    conv2d_backward_weights_gemm_optimized(d_grad_conv1_out, d_input, d_w_conv1, d_col_buffer, H, W, C, H, W, 256, 3, 1, 1);
    conv2d_backward_input_gemm_optimized(d_grad_conv1_out, d_w_conv1, d_input, d_col_buffer, H, W, C, H, W, 256, 3, 1, 1);
    cudaDeviceSynchronize();
    end = high_resolution_clock::now();
    bwd_times.push_back({"Conv1", duration<float, milli>(end - start).count()});
    auto total_bwd_end = high_resolution_clock::now();
    float total_bwd = duration<float, milli>(total_bwd_end - total_bwd_start).count();
    for (auto& p : bwd_times) {
        cout << left << setw(12) << p.first << fixed << setprecision(3) << setw(8) << p.second << " ms  (" 
             << setprecision(1) << setw(5) << (p.second/total_bwd*100) << "%)" << endl;
    }
    cout << "\nBACKWARD TOTAL: " << fixed << setprecision(3) << total_bwd << " ms" << endl;
    cout << "\n============================================" << endl;
    cout << "SUMMARY:" << endl;
    cout << "  Forward:  " << fixed << setprecision(3) << total_fwd << " ms" << endl;
    cout << "  Backward: " << fixed << setprecision(3) << total_bwd << " ms" << endl;
    cout << "  Ratio:    " << fixed << setprecision(2) << (total_bwd / total_fwd) << "x" << endl;
    cout << "============================================" << endl;
    return 0;
}
