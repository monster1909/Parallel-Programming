{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfWp2iVjeJcm",
        "outputId": "b5af5f1c-5f36-45ad-b91e-4d585ff30f91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sun Dec 14 11:28:30 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   60C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWlMPx7ha4xe"
      },
      "source": [
        "# Clone Repo\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdfb3b41",
        "outputId": "6d941594-3797-4548-faab-93e49d20d0be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Parallel-Programming'...\n",
            "remote: Enumerating objects: 624, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 624 (delta 133), reused 134 (delta 109), pack-reused 447 (from 1)\u001b[K\n",
            "Receiving objects: 100% (624/624), 165.75 MiB | 20.23 MiB/s, done.\n",
            "Resolving deltas: 100% (318/318), done.\n",
            "Updating files: 100% (142/142), done.\n",
            "/content/Parallel-Programming\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/monster1909/Parallel-Programming.git\n",
        "%cd Parallel-Programming"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmudAQpuDFW1"
      },
      "source": [
        "# Optimizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "adHvtXDG5eWd"
      },
      "source": [
        "## Phase 2\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gkzVy2K_5gIZ",
        "outputId": "0388434e-1221-4f93-8284-917ea7ab995a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Parallel-Programming/phase2_gpu_basic\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Parallel-Programming/phase2_gpu_basic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxUp37nc5oK_",
        "outputId": "2b323ca2-b6e7-402a-a7ad-135b56f39f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found NVCC at: /usr/local/cuda/bin/nvcc\n",
            "/usr/local/cuda/bin/nvcc -std=c++17 -I Include src/main_gpu.cu src/autoencoder.cu src/utils/cuda_utils.cpp src/utils/gpu_memory.cu src/kernels/conv2d.cu src/kernels/maxpool.cu src/kernels/relu.cu src/kernels/upsample.cu -o run_gpu\n",
            "/usr/local/cuda/bin/nvcc -std=c++17 -I Include src/main_gpu_test.cu src/autoencoder.cu src/utils/cuda_utils.cpp src/utils/gpu_memory.cu src/kernels/conv2d.cu src/kernels/maxpool.cu src/kernels/relu.cu src/kernels/upsample.cu -o test_gpu\n"
          ]
        }
      ],
      "source": [
        "!make -f MAKEFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jghmV3Ix5rSn",
        "outputId": "7b2e0f99-6a9a-493e-d3fa-826b43f1f365"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 2: GPU Basic Autoencoder Test (QUICK TEST) =====\n",
            "[INFO] Loading image from CIFAR-10 dataset...\n",
            "[INFO] File: ../Data/cifar-10-batches-bin/data_batch_1.bin\n",
            "[INFO] Image index: 0\n",
            "[INFO] Image loaded successfully!\n",
            "[INFO] Image label: 6\n",
            "[INFO] Image size: 3x32x32\n",
            "\n",
            "===== INPUT SAMPLE VALUES (first 10 pixels) =====\n",
            "0.231373 0.168627 0.196078 0.266667 0.384314 0.466667 0.545098 0.568627 0.584314 0.584314 \n",
            "\n",
            "[INFO] Creating autoencoder...\n",
            "[INFO] Initializing GPU Autoencoder (Phase 2 - Full Architecture)...\n",
            "[INFO] GPU Autoencoder initialization done.\n",
            "\n",
            "========================================\n",
            "DETAILED LAYER TIMING (1 image)\n",
            "========================================\n",
            "\n",
            "===== FORWARD PASS START =====\n",
            "[INPUT] First 10 pixels: 0.231373 0.168627 0.196078 0.266667 0.384314 0.466667 0.545098 0.568627 0.584314 0.584314 \n",
            "\n",
            "\n",
            "===== TIME BREAKDOWN =====\n",
            "Conv1:      44.0176 ms  (78.1589%)\n",
            "ReLU1:      4.03194 ms  (7.15922%)\n",
            "MaxPool1:   3.74413 ms  (6.64818%)\n",
            "Conv2:      0.007904 ms  (0.0140346%)\n",
            "ReLU2:      0.006816 ms  (0.0121027%)\n",
            "MaxPool2:   0.00672 ms  (0.0119322%)\n",
            "DecodeConv1:0.00784 ms  (0.0139209%)\n",
            "Upsample1:  4.4729 ms  (7.9422%)\n",
            "DecodeConv2:0.007328 ms  (0.0130118%)\n",
            "Upsample2:  0.007424 ms  (0.0131823%)\n",
            "FinalConv:  0.00752 ms  (0.0133527%)\n",
            "----------------------------------\n",
            "TOTAL FORWARD TIME: 56.3181 ms\n",
            "==================================\n",
            "\n",
            "===== OUTPUT SAMPLE VALUES (first 10 pixels) =====\n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "\n",
            "===== DONE =====\n"
          ]
        }
      ],
      "source": [
        "!./test_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d80Kzvy5w5p",
        "outputId": "9aeecfe5-2de6-44c3-bd8f-0a0c7ff29766"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 2: GPU Basic Autoencoder Test =====\n",
            "[INFO] Loading image from CIFAR-10 dataset...\n",
            "[INFO] File: ../Data/cifar-10-batches-bin/data_batch_1.bin\n",
            "[INFO] Image index: 0\n",
            "[INFO] Image loaded successfully!\n",
            "[INFO] Image label: 6\n",
            "[INFO] Image size: 3x32x32\n",
            "\n",
            "===== INPUT SAMPLE VALUES (first 10 pixels) =====\n",
            "0.231373 0.168627 0.196078 0.266667 0.384314 0.466667 0.545098 0.568627 0.584314 0.584314 \n",
            "[INFO] Initializing GPU Autoencoder (Phase 2 - Full Architecture)...\n",
            "[INFO] GPU Autoencoder initialization done.\n",
            "\n",
            "[INFO] Benchmarking 60000 images...\n",
            "[INFO] Running GPU forward pass (verbose disabled for benchmark)...\n",
            "[PROGRESS] 60000/60000 (100.0%)    \n",
            "\n",
            "========================================\n",
            "BENCHMARK RESULTS (60,000 images)\n",
            "========================================\n",
            "Total Time:           10974.7 ms\n",
            "Total Time:           10.9747 seconds\n",
            "Avg Time per Image:   0.182912 ms\n",
            "Target Requirement:    < 20.0 seconds\n",
            ">>> RESULT: PASSED (Fast enough) <<<\n",
            "========================================\n",
            "\n",
            "===== OUTPUT SAMPLE VALUES (first 10 pixels from last image) =====\n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "\n",
            "===== DONE =====\n"
          ]
        }
      ],
      "source": [
        "!./run_gpu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUF_iz_qawQC"
      },
      "source": [
        "## Phase 3 - Version 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXIDRs2iYXKw",
        "outputId": "fefffed9-22c5-4614-d3f6-d65e9d293655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Parallel-Programming/phase3_gpu_optimized\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Parallel-Programming/phase3_gpu_optimized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cDBEuQfYZ4o",
        "outputId": "6c1f9009-8393-4950-d3a4-e5b643c2bb94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found NVCC at: /usr/local/cuda/bin/nvcc\n",
            "/usr/local/cuda/bin/nvcc -O3 -std=c++17 -I./Include  src/main_gpu_optimized.cu src/autoencoder.cu src/kernels/im2col.cu src/kernels/gemm.cu src/kernels/relu.cu src/kernels/maxpool.cu src/kernels/upsample.cu src/utils/cuda_utils.cpp src/utils/gpu_memory.cu -o run_phase3\n",
            "/usr/local/cuda/bin/nvcc -O3 -std=c++17 -I./Include  src/main_gpu_test.cu src/autoencoder.cu src/kernels/im2col.cu src/kernels/gemm.cu src/kernels/relu.cu src/kernels/maxpool.cu src/kernels/upsample.cu src/utils/cuda_utils.cpp src/utils/gpu_memory.cu -o test_gpu\n"
          ]
        }
      ],
      "source": [
        "!make -f MAKEFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFOeh0mLYcKz",
        "outputId": "34126ab6-6e43-458d-c3dd-2521b7501d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 3: GPU Optimized Autoencoder Test (DETAILED TIMING) =====\n",
            "[INFO] Loading image from CIFAR-10 dataset...\n",
            "[INFO] File: ../Data/cifar-10-batches-bin/data_batch_1.bin\n",
            "[INFO] Image index: 0\n",
            "[INFO] Image loaded successfully!\n",
            "[INFO] Image label: 6\n",
            "[INFO] Image size: 3x32x32\n",
            "\n",
            "===== INPUT SAMPLE VALUES (first 10 pixels) =====\n",
            "0.231373 0.168627 0.196078 0.266667 0.384314 0.466667 0.545098 0.568627 0.584314 0.584314 \n",
            "\n",
            "[INFO] Creating autoencoder...\n",
            "[INFO] Initializing Phase 3 Autoencoder (Im2Col + GEMM)...\n",
            "[INFO] GPU Memory Allocated. Ready for Phase 3.\n",
            "\n",
            "========================================\n",
            "DETAILED LAYER TIMING (1 image)\n",
            "========================================\n",
            "\n",
            "===== FORWARD PASS START =====\n",
            "\n",
            "===== TIME BREAKDOWN =====\n",
            "Conv1:        11.3152 ms  (49.997%)\n",
            "ReLU1:        3.69462 ms  (16.3249%)\n",
            "MaxPool1:     3.66992 ms  (16.2158%)\n",
            "Conv2:        0.006464 ms  (0.0285616%)\n",
            "ReLU2:        0.006112 ms  (0.0270063%)\n",
            "MaxPool2:     0.007424 ms  (0.0328034%)\n",
            "DecodeConv1:  0.00736 ms  (0.0325206%)\n",
            "ReLU_Dec1:    0.00736 ms  (0.0325206%)\n",
            "Upsample1:    3.88678 ms  (17.174%)\n",
            "DecodeConv2:  0.00704 ms  (0.0311067%)\n",
            "ReLU_Dec2:    0.008192 ms  (0.0361969%)\n",
            "Upsample2:    0.007904 ms  (0.0349243%)\n",
            "FinalConv:    0.007392 ms  (0.032662%)\n",
            "----------------------------------\n",
            "TOTAL FORWARD TIME: 22.6318 ms\n",
            "==================================\n",
            "\n",
            "===== OUTPUT SAMPLE VALUES (first 10 pixels) =====\n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "\n",
            "===== DONE =====\n"
          ]
        }
      ],
      "source": [
        "!./test_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "boF-rWtzYgEd",
        "outputId": "0ac9f143-2575-4b71-c4dc-93faf9181eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== PHASE 3: BATCH PERFORMANCE TEST ==========\n",
            "[INFO] Initializing Phase 3 Autoencoder (Im2Col + GEMM)...\n",
            "[INFO] GPU Memory Allocated. Ready for Phase 3.\n",
            "[INFO] Benchmarking 60000 images...\n",
            "[INFO] Running GPU forward pass (verbose disabled for benchmark)...\n",
            "[PROGRESS] 60000/60000 (100.0%)    \n",
            "\n",
            "========================================\n",
            "BENCHMARK RESULTS (60,000 images)\n",
            "========================================\n",
            "Total Time:           1566.97 ms\n",
            "Total Time:           1.56697 seconds\n",
            "Avg Time per Image:   0.0261161 ms\n",
            "Target Requirement:   < 20.0 seconds\n",
            ">>> RESULT: PASSED (Fast enough) <<<\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "!./run_phase3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRd9jGGmDOoU"
      },
      "source": [
        "## Phase 3 - Version 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anNSXwDfIIhD",
        "outputId": "25b498c5-f051-4d2b-c8f3-833c4d2c095a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Parallel-Programming/phase3_gpu_optimized_v2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Parallel-Programming/phase3_gpu_optimized_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPTFr-I4P-HE",
        "outputId": "9859a8b1-ac40-4fb5-db33-5489e8e3afda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found NVCC at: /usr/local/cuda/bin/nvcc\n",
            "/usr/local/cuda/bin/nvcc -O3 -std=c++17 -I./Include  src/main_gpu_optimized.cu src/autoencoder.cu src/kernels/im2col.cu src/kernels/gemm.cu src/kernels/relu.cu src/kernels/maxpool.cu src/kernels/upsample.cu src/utils/cuda_utils.cpp src/utils/gpu_memory.cu -o run_phase3\n",
            "/usr/local/cuda/bin/nvcc -O3 -std=c++17 -I./Include  src/main_gpu_test.cu src/autoencoder.cu src/kernels/im2col.cu src/kernels/gemm.cu src/kernels/relu.cu src/kernels/maxpool.cu src/kernels/upsample.cu src/utils/gpu_memory.cu -o test_gpu\n",
            "/usr/local/cuda/bin/nvcc -O3 -std=c++17 -I./Include  src/main_feature_extraction.cu src/autoencoder.cu src/kernels/im2col.cu src/kernels/gemm.cu src/kernels/relu.cu src/kernels/maxpool.cu src/kernels/upsample.cu src/utils/gpu_memory.cu -o feature_extract\n"
          ]
        }
      ],
      "source": [
        "!make -f MAKEFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqLT66r7XOZD",
        "outputId": "beea930b-6eb8-4140-a8cb-3d3867e4a6c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 3 V2: Batched GPU Autoencoder Test (DETAILED TIMING) =====\n",
            "[INFO] Loading image from CIFAR-10 dataset...\n",
            "[INFO] File: ../Data/cifar-10-batches-bin/data_batch_1.bin\n",
            "[INFO] Image index: 0\n",
            "[INFO] Image loaded successfully!\n",
            "[INFO] Image label: 6\n",
            "[INFO] Image size: 3x32x32\n",
            "[INFO] Batch size: 1\n",
            "\n",
            "===== INPUT SAMPLE VALUES (first 10 pixels) =====\n",
            "0.231373 0.168627 0.196078 0.266667 0.384314 0.466667 0.545098 0.568627 0.584314 0.584314 \n",
            "\n",
            "[INFO] Creating batched autoencoder...\n",
            "[INFO] Init Batch Autoencoder (Max Batch: 1)...\n",
            "\n",
            "========================================\n",
            "DETAILED LAYER TIMING (1 batch of 1 images)\n",
            "========================================\n",
            "\n",
            "===== FORWARD PASS START (Batch Size: 1) =====\n",
            "\n",
            "===== TIME BREAKDOWN =====\n",
            "Conv1:        12.0194 ms  (62.6864%)\n",
            "ReLU1:        0 ms  (0%)\n",
            "MaxPool1:     3.62314 ms  (18.8963%)\n",
            "Conv2:        0.007008 ms  (0.0365499%)\n",
            "ReLU2:        0 ms  (0%)\n",
            "MaxPool2:     0.006592 ms  (0.0343803%)\n",
            "DecodeConv1:  0.00624 ms  (0.0325444%)\n",
            "ReLU_Dec1:    0 ms  (0%)\n",
            "Upsample1:    3.49101 ms  (18.2072%)\n",
            "DecodeConv2:  0.006784 ms  (0.0353816%)\n",
            "ReLU_Dec2:    0 ms  (0%)\n",
            "Upsample2:    0.006112 ms  (0.0318769%)\n",
            "FinalConv:    0.007552 ms  (0.0393871%)\n",
            "----------------------------------\n",
            "TOTAL FORWARD TIME: 19.1738 ms\n",
            "==================================\n",
            "\n",
            "===== OUTPUT SAMPLE VALUES (first 10 pixels of first image) =====\n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "\n",
            "===== DONE =====\n"
          ]
        }
      ],
      "source": [
        "!./test_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oD8_fgLHQBcj",
        "outputId": "4b4fc805-9ca3-467c-a379-0e2f1c84b551"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== PHASE 3 v2: BATCHED OPTIMIZATION ==========\n",
            "[INFO] Init Batch Autoencoder (Max Batch: 32)...\n",
            "[INFO] Benchmarking 60000 images...\n",
            "[INFO] Using batch size: 32\n",
            "[INFO] Number of batches: 1875 (processing 60000 images)\n",
            "[INFO] Running GPU forward pass (verbose disabled for benchmark)...\n",
            "[PROGRESS] Batch 1875/1875 (100.0%) - 60000 images    \n",
            "\n",
            "========================================\n",
            "BENCHMARK RESULTS (60,000 images)\n",
            "========================================\n",
            "Total Time (60000 imgs): 637.331 ms\n",
            "Total Time:           0.637331 seconds\n",
            "Projected 60k Time:   0.637331 seconds\n",
            "Avg Time per Image:   0.0106222 ms\n",
            "Target Requirement:   < 20.0 seconds\n",
            ">>> RESULT: PASSED (Fast enough) <<<\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "!./run_phase3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70KA7bhKQHCT",
        "outputId": "825b1c89-a1a3-4ff5-a6d2-068831e6871c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "========== PHASE 3 V2: FEATURE EXTRACTION BENCHMARK ==========\n",
            "[INFO] Init Batch Autoencoder (Max Batch: 32)...\n",
            "[INFO] Benchmarking feature extraction for 60000 images...\n",
            "[INFO] Using batch size: 32\n",
            "[INFO] Number of batches: 1875 (processing 60000 images)\n",
            "[INFO] Running feature extraction (encoder only)...\n",
            "[PROGRESS] Batch 1875/1875 (100.0%) - 60000 images    \n",
            "\n",
            "========================================\n",
            "FEATURE EXTRACTION RESULTS (60,000 images)\n",
            "========================================\n",
            "Total Time (60000 imgs): 901.791 ms\n",
            "Total Time:           0.901791 seconds\n",
            "Projected 60k Time:   0.901791 seconds\n",
            "Avg Time per Image:   0.0150298 ms\n",
            "Target Requirement:   < 20.0 seconds\n",
            ">>> RESULT: PASSED (Fast enough) <<<\n",
            "========================================\n"
          ]
        }
      ],
      "source": [
        "!./feature_extract"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m_xdTI0tC_5j"
      },
      "source": [
        "# Training autoencoder\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKdhsXL05IK4"
      },
      "source": [
        "## Phase 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I899wChJ5Z25",
        "outputId": "c62ee053-df31-457c-ec56-5dbeb24cb84a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Parallel-Programming/train/P2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Parallel-Programming/train/P2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uw9ExRf5b-d",
        "outputId": "a1c56d44-3202-4258-8479-2af7dc679da1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Phase 2 Training...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase2_gpu_basic/Include -I../include train_phase2.cu ../../phase2_gpu_basic/src/kernels/conv2d.cu ../../phase2_gpu_basic/src/kernels/relu.cu ../../phase2_gpu_basic/src/kernels/maxpool.cu ../../phase2_gpu_basic/src/kernels/upsample.cu ../src/kernels/conv2d_backward.cu ../src/kernels/relu_backward.cu ../src/kernels/maxpool_backward.cu ../src/kernels/upsample_backward.cu ../src/kernels/mse_loss.cu ../src/sgd_optimizer.cu ../src/data_loader.cpp ../src/logger.cpp -o train_phase2\n",
            "Build complete: train_phase2\n"
          ]
        }
      ],
      "source": [
        "!make -f MAKEFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Hlmc8DZB5dIP"
      },
      "outputs": [],
      "source": [
        "!mkdir -p logs\n",
        "!mkdir -p weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RYtCpyP5diK",
        "outputId": "dd29e499-2197-4577-bb9a-71b10a8e7a79"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 2 Training =====\n",
            "[DataLoader] Loading CIFAR-10 TRAIN dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 5 batch file(s)...\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Batch size: 32, Num batches: 1563\n",
            "[2025-12-14 11:30:22] Training started: epochs=20, batch_size=32, lr=0.001000\n",
            "[INFO] Initializing weights with Xavier initialization (seed=42)...\n",
            "[INFO] Memory allocated, starting training...\n",
            "Training Epoch 1/20...\n",
            "  0% - Loss: 0.248877 - Time: 13s\n",
            "  5% - Loss: 0.289682 - Time: 27s\n",
            "  10% - Loss: 0.232042 - Time: 41s\n",
            "  15% - Loss: 0.209737 - Time: 55s\n",
            "  20% - Loss: 0.198254 - Time: 70s\n",
            "  25% - Loss: 0.167087 - Time: 84s\n",
            "  30% - Loss: 0.152602 - Time: 98s\n",
            "  35% - Loss: 0.131689 - Time: 112s\n",
            "  40% - Loss: 0.146725 - Time: 126s\n",
            "  45% - Loss: 0.111125 - Time: 141s\n",
            "  50% - Loss: 0.097777 - Time: 155s\n",
            "  55% - Loss: 0.087253 - Time: 169s\n",
            "  60% - Loss: 0.089562 - Time: 183s\n",
            "  65% - Loss: 0.067062 - Time: 198s\n",
            "  70% - Loss: 0.058864 - Time: 212s\n",
            "  75% - Loss: 0.069617 - Time: 226s\n",
            "  80% - Loss: 0.069804 - Time: 240s\n",
            "  85% - Loss: 0.054868 - Time: 254s\n",
            "  90% - Loss: 0.061553 - Time: 269s\n",
            "  95% - Loss: 0.068811 - Time: 283s\n",
            "  100% - Loss: 0.022995 - Time: 283s\n",
            "Epoch 1 complete - Avg Loss: 0.133959 (Best: 0.133959) - Time: 283.91s\n",
            "\n",
            "[2025-12-14 11:35:06] Epoch   1 | Loss: 0.133959 | Time: 283.91s\n",
            "[INFO] Saved weights to weights/phase2_epoch_1.bin\n",
            "Training Epoch 2/20...\n",
            "  0% - Loss: 0.065945 - Time: 14s\n",
            "  5% - Loss: 0.051076 - Time: 28s\n",
            "  10% - Loss: 0.060491 - Time: 42s\n",
            "  15% - Loss: 0.059168 - Time: 56s\n",
            "  20% - Loss: 0.057513 - Time: 71s\n",
            "  25% - Loss: 0.060076 - Time: 85s\n",
            "  30% - Loss: 0.052831 - Time: 99s\n",
            "  35% - Loss: 0.061533 - Time: 113s\n",
            "  40% - Loss: 0.059372 - Time: 127s\n",
            "  45% - Loss: 0.056300 - Time: 142s\n",
            "  50% - Loss: 0.058171 - Time: 156s\n",
            "  55% - Loss: 0.051422 - Time: 170s\n",
            "  60% - Loss: 0.061083 - Time: 184s\n",
            "  65% - Loss: 0.061454 - Time: 198s\n",
            "  70% - Loss: 0.051787 - Time: 213s\n",
            "  75% - Loss: 0.049654 - Time: 227s\n",
            "  80% - Loss: 0.065405 - Time: 241s\n",
            "  85% - Loss: 0.058394 - Time: 255s\n",
            "  90% - Loss: 0.055636 - Time: 269s\n",
            "  95% - Loss: 0.068911 - Time: 284s\n",
            "  100% - Loss: 0.024086 - Time: 284s\n",
            "Epoch 2 complete - Avg Loss: 0.057380 (Best: 0.057380) - Time: 284.78s\n",
            "\n",
            "[2025-12-14 11:39:51] Epoch   2 | Loss: 0.057380 | Time: 284.78s\n",
            "[INFO] Saved weights to weights/phase2_epoch_2.bin\n",
            "Training Epoch 3/20...\n",
            "  0% - Loss: 0.054674 - Time: 14s\n",
            "  5% - Loss: 0.066196 - Time: 28s\n",
            "  10% - Loss: 0.053218 - Time: 42s\n",
            "  15% - Loss: 0.046764 - Time: 56s\n",
            "  20% - Loss: 0.049804 - Time: 71s\n",
            "  25% - Loss: 0.048217 - Time: 85s\n",
            "  30% - Loss: 0.059149 - Time: 99s\n",
            "  35% - Loss: 0.051400 - Time: 113s\n",
            "  40% - Loss: 0.052565 - Time: 127s\n",
            "  45% - Loss: 0.057176 - Time: 142s\n",
            "  50% - Loss: 0.062327 - Time: 156s\n",
            "  55% - Loss: 0.050143 - Time: 170s\n",
            "  60% - Loss: 0.054785 - Time: 184s\n",
            "  65% - Loss: 0.055855 - Time: 199s\n",
            "  70% - Loss: 0.048499 - Time: 213s\n",
            "  75% - Loss: 0.061314 - Time: 227s\n",
            "  80% - Loss: 0.053672 - Time: 241s\n",
            "  85% - Loss: 0.066172 - Time: 255s\n",
            "  90% - Loss: 0.052485 - Time: 270s\n",
            "  95% - Loss: 0.050364 - Time: 284s\n",
            "  100% - Loss: 0.021504 - Time: 284s\n",
            "Epoch 3 complete - Avg Loss: 0.053891 (Best: 0.053891) - Time: 284.87s\n",
            "\n",
            "[2025-12-14 11:44:36] Epoch   3 | Loss: 0.053891 | Time: 284.87s\n",
            "[INFO] Saved weights to weights/phase2_epoch_3.bin\n",
            "Training Epoch 4/20...\n",
            "  0% - Loss: 0.056425 - Time: 14s\n",
            "  5% - Loss: 0.056492 - Time: 28s\n",
            "  10% - Loss: 0.047491 - Time: 42s\n",
            "  15% - Loss: 0.053862 - Time: 56s\n",
            "  20% - Loss: 0.047288 - Time: 71s\n",
            "  25% - Loss: 0.048963 - Time: 85s\n",
            "  30% - Loss: 0.061446 - Time: 99s\n",
            "  35% - Loss: 0.059293 - Time: 113s\n",
            "  40% - Loss: 0.051417 - Time: 127s\n",
            "  45% - Loss: 0.054098 - Time: 142s\n",
            "  50% - Loss: 0.046881 - Time: 156s\n",
            "  55% - Loss: 0.052804 - Time: 170s\n",
            "  60% - Loss: 0.049850 - Time: 184s\n",
            "  65% - Loss: 0.054804 - Time: 199s\n",
            "  70% - Loss: 0.056046 - Time: 213s\n",
            "  75% - Loss: 0.054437 - Time: 227s\n",
            "  80% - Loss: 0.050516 - Time: 241s\n",
            "  85% - Loss: 0.049994 - Time: 255s\n",
            "  90% - Loss: 0.052118 - Time: 270s\n",
            "  95% - Loss: 0.051431 - Time: 284s\n",
            "  100% - Loss: 0.026432 - Time: 284s\n",
            "Epoch 4 complete - Avg Loss: 0.051866 (Best: 0.051866) - Time: 284.98s\n",
            "\n",
            "[2025-12-14 11:49:21] Epoch   4 | Loss: 0.051866 | Time: 284.98s\n",
            "[INFO] Saved weights to weights/phase2_epoch_4.bin\n",
            "Training Epoch 5/20...\n",
            "  0% - Loss: 0.054110 - Time: 14s\n",
            "  5% - Loss: 0.052232 - Time: 28s\n",
            "  10% - Loss: 0.051719 - Time: 42s\n",
            "  15% - Loss: 0.055628 - Time: 56s\n",
            "  20% - Loss: 0.051481 - Time: 71s\n",
            "  25% - Loss: 0.056332 - Time: 85s\n",
            "  30% - Loss: 0.050513 - Time: 99s\n",
            "  35% - Loss: 0.045657 - Time: 113s\n",
            "  40% - Loss: 0.059941 - Time: 128s\n",
            "  45% - Loss: 0.055671 - Time: 142s\n",
            "  50% - Loss: 0.050201 - Time: 156s\n",
            "  55% - Loss: 0.055023 - Time: 170s\n",
            "  60% - Loss: 0.052346 - Time: 184s\n",
            "  65% - Loss: 0.054338 - Time: 199s\n",
            "  70% - Loss: 0.054858 - Time: 213s\n",
            "  75% - Loss: 0.054903 - Time: 227s\n",
            "  80% - Loss: 0.049100 - Time: 241s\n",
            "  85% - Loss: 0.051901 - Time: 256s\n",
            "  90% - Loss: 0.054499 - Time: 270s\n",
            "  95% - Loss: 0.052273 - Time: 284s\n",
            "  100% - Loss: 0.024847 - Time: 285s\n",
            "Epoch 5 complete - Avg Loss: 0.051476 (Best: 0.051476) - Time: 285.04s\n",
            "\n",
            "[2025-12-14 11:54:06] Epoch   5 | Loss: 0.051476 | Time: 285.04s\n",
            "[INFO] Saved weights to weights/phase2_epoch_5.bin\n",
            "Training Epoch 6/20...\n",
            "  0% - Loss: 0.051082 - Time: 14s\n",
            "  5% - Loss: 0.046150 - Time: 28s\n",
            "  10% - Loss: 0.055947 - Time: 42s\n",
            "  15% - Loss: 0.051058 - Time: 56s\n",
            "  20% - Loss: 0.055295 - Time: 71s\n",
            "  25% - Loss: 0.048097 - Time: 85s\n",
            "  30% - Loss: 0.048669 - Time: 99s\n",
            "  35% - Loss: 0.054547 - Time: 113s\n",
            "  40% - Loss: 0.048923 - Time: 128s\n",
            "  45% - Loss: 0.045994 - Time: 142s\n",
            "  50% - Loss: 0.048631 - Time: 156s\n",
            "  55% - Loss: 0.051112 - Time: 170s\n",
            "  60% - Loss: 0.051008 - Time: 184s\n",
            "  65% - Loss: 0.045793 - Time: 199s\n",
            "  70% - Loss: 0.044030 - Time: 213s\n",
            "  75% - Loss: 0.046953 - Time: 227s\n",
            "  80% - Loss: 0.055998 - Time: 241s\n",
            "  85% - Loss: 0.054100 - Time: 256s\n",
            "  90% - Loss: 0.048673 - Time: 270s\n",
            "  95% - Loss: 0.046752 - Time: 284s\n",
            "  100% - Loss: 0.023999 - Time: 285s\n",
            "Epoch 6 complete - Avg Loss: 0.052616 (Best: 0.051476, No improvement: 1/3) - Time: 285.08s\n",
            "\n",
            "[2025-12-14 11:58:51] Epoch   6 | Loss: 0.052616 | Time: 285.08s\n",
            "[INFO] Saved weights to weights/phase2_epoch_6.bin\n",
            "Training Epoch 7/20...\n",
            "  0% - Loss: 0.053889 - Time: 14s\n",
            "  5% - Loss: 0.061740 - Time: 28s\n",
            "  10% - Loss: 0.060741 - Time: 42s\n",
            "  15% - Loss: 0.057015 - Time: 56s\n",
            "  20% - Loss: 0.052855 - Time: 71s\n",
            "  25% - Loss: 0.049142 - Time: 85s\n",
            "  30% - Loss: 0.055590 - Time: 99s\n",
            "  35% - Loss: 0.059626 - Time: 113s\n",
            "  40% - Loss: 0.046215 - Time: 128s\n",
            "  45% - Loss: 0.051313 - Time: 142s\n",
            "  50% - Loss: 0.048027 - Time: 156s\n",
            "  55% - Loss: 0.055267 - Time: 170s\n",
            "  60% - Loss: 0.053460 - Time: 184s\n",
            "  65% - Loss: 0.048520 - Time: 199s\n",
            "  70% - Loss: 0.068022 - Time: 213s\n",
            "  75% - Loss: 0.058516 - Time: 227s\n",
            "  80% - Loss: 0.058001 - Time: 241s\n",
            "  85% - Loss: 0.049071 - Time: 255s\n",
            "  90% - Loss: 0.065323 - Time: 270s\n",
            "  95% - Loss: 0.049344 - Time: 284s\n",
            "  100% - Loss: 0.024656 - Time: 284s\n",
            "Epoch 7 complete - Avg Loss: 0.055000 (Best: 0.051476, No improvement: 2/3) - Time: 284.80s\n",
            "\n",
            "[2025-12-14 12:03:36] Epoch   7 | Loss: 0.055000 | Time: 284.80s\n",
            "[INFO] Saved weights to weights/phase2_epoch_7.bin\n",
            "Training Epoch 8/20...\n",
            "  0% - Loss: 0.048840 - Time: 14s\n",
            "  5% - Loss: 0.058094 - Time: 28s\n",
            "  10% - Loss: 0.051405 - Time: 42s\n",
            "  15% - Loss: 0.051046 - Time: 56s\n",
            "  20% - Loss: 0.048154 - Time: 71s\n",
            "  25% - Loss: 0.064180 - Time: 85s\n",
            "  30% - Loss: 0.055356 - Time: 99s\n",
            "  35% - Loss: 0.058278 - Time: 113s\n",
            "  40% - Loss: 0.067867 - Time: 127s\n",
            "  45% - Loss: 0.053840 - Time: 142s\n",
            "  50% - Loss: 0.059313 - Time: 156s\n",
            "  55% - Loss: 0.060728 - Time: 170s\n",
            "  60% - Loss: 0.060694 - Time: 184s\n",
            "  65% - Loss: 0.063567 - Time: 198s\n",
            "  70% - Loss: 0.055485 - Time: 213s\n",
            "  75% - Loss: 0.059948 - Time: 227s\n",
            "  80% - Loss: 0.059259 - Time: 241s\n",
            "  85% - Loss: 0.062895 - Time: 255s\n",
            "  90% - Loss: 0.066153 - Time: 269s\n",
            "  95% - Loss: 0.062460 - Time: 284s\n",
            "  100% - Loss: 0.031702 - Time: 284s\n",
            "Epoch 8 complete - Avg Loss: 0.058235 (Best: 0.051476, No improvement: 3/3) - Time: 284.69s\n",
            "\n",
            "[INFO] Early stopping triggered! No improvement for 3 epochs.\n",
            "[INFO] Best loss: 0.051476 at epoch 5\n",
            "\n",
            "[INFO] Training stopped early. Generating summary...\n",
            "[INFO] Generating sample reconstructed images...\n",
            "[WARNING] CUDA error during forward pass: invalid argument\n",
            "\n",
            "========================================\n",
            "       TRAINING SUMMARY\n",
            "========================================\n",
            "\n",
            "[EARLY STOP] Training stopped after epoch 8 (no improvement for 3 epochs)\n",
            "\n",
            "--- Training Performance ---\n",
            "Total training time: 2278.19 seconds\n",
            "Number of epochs completed: 8\n",
            "Average time per epoch: 284.77 seconds\n",
            "\n",
            "Training Time Per Epoch:\n",
            "  Epoch   1: 283.91 seconds\n",
            "  Epoch   2: 284.78 seconds\n",
            "  Epoch   3: 284.87 seconds\n",
            "  Epoch   4: 284.98 seconds\n",
            "  Epoch   5: 285.04 seconds\n",
            "  Epoch   6: 285.08 seconds\n",
            "  Epoch   7: 284.80 seconds\n",
            "  Epoch   8: 284.69 seconds\n",
            "Final reconstruction loss: 0.051476\n",
            "\n",
            "--- Memory Usage ---\n",
            "GPU Memory Used: 114 MB / 15095 MB\n",
            "GPU Memory Usage: 0.8%\n",
            "\n",
            "--- Sample Images ---\n",
            "âœ— Sample image generation failed or was disabled\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "TRAINING SUMMARY\n",
            "========================================\n",
            "Total Training Time: 2278.19 seconds\n",
            "Final Reconstruction Loss: 0.051476\n",
            "\n",
            "Training Time Per Epoch:\n",
            "  Epoch   1: 283.91 seconds\n",
            "  Epoch   2: 284.78 seconds\n",
            "  Epoch   3: 284.87 seconds\n",
            "  Epoch   4: 284.98 seconds\n",
            "  Epoch   5: 285.04 seconds\n",
            "  Epoch   6: 285.08 seconds\n",
            "  Epoch   7: 284.80 seconds\n",
            "  Epoch   8: 284.69 seconds\n",
            "\n",
            "GPU Memory Usage:\n",
            "  Used: 114 MB\n",
            "  Total: 15095 MB\n",
            "  Usage: 0.76%\n",
            "\n",
            "Sample Reconstructed Images:\n",
            "  (Check logs directory for sample_original_*.ppm and sample_reconstructed_*.ppm files)\n",
            "========================================\n",
            "\n",
            "[2025-12-14 12:08:20] Training completed\n",
            "===== Training Complete =====\n"
          ]
        }
      ],
      "source": [
        "!./train_phase2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZ97_ET55hMg",
        "outputId": "8f0473a0-2616-490e-876f-6f2a7e24eee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Phase 2 Inference...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase2_gpu_basic/Include -I../include infer_phase2.cu ../../phase2_gpu_basic/src/kernels/conv2d.cu ../../phase2_gpu_basic/src/kernels/relu.cu ../../phase2_gpu_basic/src/kernels/maxpool.cu ../../phase2_gpu_basic/src/kernels/upsample.cu ../src/kernels/mse_loss.cu ../src/data_loader.cpp -o infer_phase2\n",
            "Build complete: infer_phase2\n"
          ]
        }
      ],
      "source": [
        "!make -f Makefile.infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uku9LRk45lLA",
        "outputId": "6f21ac82-6cbd-4c4d-cd64-856976522f0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 2 Inference =====\n",
            "[INFO] Loading weights from: weights/phase2_epoch_5.bin\n",
            "[INFO] Loaded weights successfully\n",
            "[DataLoader] Loading CIFAR-10 TEST dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 1 batch file(s)...\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Batch size: 32, Num batches: 313\n",
            "[INFO] Running inference on 10000 test images...\n",
            "[INFO] Displaying first 10 results...\n",
            "\n",
            "Image 1/10000 - Reconstruction Loss: 0.0407256\n",
            "Image 2/10000 - Reconstruction Loss: 0.0728661\n",
            "Image 3/10000 - Reconstruction Loss: 0.0532947\n",
            "Image 4/10000 - Reconstruction Loss: 0.0554641\n",
            "Image 5/10000 - Reconstruction Loss: 0.0221585\n",
            "Image 6/10000 - Reconstruction Loss: 0.0282914\n",
            "Image 7/10000 - Reconstruction Loss: 0.0536521\n",
            "Image 8/10000 - Reconstruction Loss: 0.0228715\n",
            "Image 9/10000 - Reconstruction Loss: 0.0424518\n",
            "Image 10/10000 - Reconstruction Loss: 0.0850705\n",
            "Processed 4000/10000 images...\n",
            "Processed 8000/10000 images...\n",
            "Processed 10000/10000 images...\n",
            "\n",
            "[RESULT] Tested on 10000 images\n",
            "[RESULT] Average Reconstruction Loss: 0.0520342\n",
            "===== Inference Complete =====\n"
          ]
        }
      ],
      "source": [
        "!./infer_phase2 weights/phase2_epoch_5.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hndiatg5prE",
        "outputId": "cc681035-2f14-4d2a-e64a-97dde1ae9d92"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Feature Extraction...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase2_gpu_basic/Include -I../include extract_features.cu ../../phase2_gpu_basic/src/kernels/conv2d.cu ../../phase2_gpu_basic/src/kernels/relu.cu ../../phase2_gpu_basic/src/kernels/maxpool.cu ../src/data_loader.cpp -o extract_features\n",
            "Build complete: extract_features\n"
          ]
        }
      ],
      "source": [
        "!make -f Makefile.extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ap6H0O695vuF",
        "outputId": "dffa0c66-5602-4322-f487-d25a5bfa5d74"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 2 Feature Extraction =====\n",
            "[INFO] Loading weights from: weights/phase2_epoch_5.bin\n",
            "[INFO] Loaded encoder weights\n",
            "[INFO] Extracting features from 60k images...\n",
            "[INFO] Output format: Label (1 byte) + Features (8192 floats)\n",
            "[DataLoader] Loading CIFAR-10 TRAIN dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 5 batch file(s)...\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Batch size: 100, Num batches: 500\n",
            "\n",
            "[TRAIN] Processing 50000 training images...\n",
            "  Processed: 1000 images\n",
            "  Processed: 2000 images\n",
            "  Processed: 3000 images\n",
            "  Processed: 4000 images\n",
            "  Processed: 5000 images\n",
            "  Processed: 6000 images\n",
            "  Processed: 7000 images\n",
            "  Processed: 8000 images\n",
            "  Processed: 9000 images\n",
            "  Processed: 10000 images\n",
            "  Processed: 11000 images\n",
            "  Processed: 12000 images\n",
            "  Processed: 13000 images\n",
            "  Processed: 14000 images\n",
            "  Processed: 15000 images\n",
            "  Processed: 16000 images\n",
            "  Processed: 17000 images\n",
            "  Processed: 18000 images\n",
            "  Processed: 19000 images\n",
            "  Processed: 20000 images\n",
            "  Processed: 21000 images\n",
            "  Processed: 22000 images\n",
            "  Processed: 23000 images\n",
            "  Processed: 24000 images\n",
            "  Processed: 25000 images\n",
            "  Processed: 26000 images\n",
            "  Processed: 27000 images\n",
            "  Processed: 28000 images\n",
            "  Processed: 29000 images\n",
            "  Processed: 30000 images\n",
            "  Processed: 31000 images\n",
            "  Processed: 32000 images\n",
            "  Processed: 33000 images\n",
            "  Processed: 34000 images\n",
            "  Processed: 35000 images\n",
            "  Processed: 36000 images\n",
            "  Processed: 37000 images\n",
            "  Processed: 38000 images\n",
            "  Processed: 39000 images\n",
            "  Processed: 40000 images\n",
            "  Processed: 41000 images\n",
            "  Processed: 42000 images\n",
            "  Processed: 43000 images\n",
            "  Processed: 44000 images\n",
            "  Processed: 45000 images\n",
            "  Processed: 46000 images\n",
            "  Processed: 47000 images\n",
            "  Processed: 48000 images\n",
            "  Processed: 49000 images\n",
            "  Processed: 50000 images\n",
            "[DataLoader] Loading CIFAR-10 TEST dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 1 batch file(s)...\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Batch size: 100, Num batches: 100\n",
            "\n",
            "[TEST] Processing 10000 test images...\n",
            "  Processed: 51000 images\n",
            "  Processed: 52000 images\n",
            "  Processed: 53000 images\n",
            "  Processed: 54000 images\n",
            "  Processed: 55000 images\n",
            "  Processed: 56000 images\n",
            "  Processed: 57000 images\n",
            "  Processed: 58000 images\n",
            "  Processed: 59000 images\n",
            "  Processed: 60000 images\n",
            "\n",
            "[RESULT] Extracted features from 60000 images\n",
            "[INFO] Output saved to: features.bin\n",
            "[INFO] File size: 1875 MB\n",
            "[INFO] Format: Label (1 byte) + Features (8192 floats = 32768 bytes)\n",
            "===== Feature Extraction Complete =====\n"
          ]
        }
      ],
      "source": [
        "!./extract_features weights/phase2_epoch_5.bin features.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtduX4Q85Fhu"
      },
      "source": [
        "## Phase 3 - Version 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPBMu9tp6Oy0",
        "outputId": "9eaab637-4912-41fb-8548-debe24b14c8d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Parallel-Programming/train/P3_1\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Parallel-Programming/train/P3_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2rpkjd96Rnp",
        "outputId": "fbc7fae0-13c3-48fe-925b-7c82a1453b25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Phase 3_1 Training (Im2Col + GEMM)...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase3_gpu_optimized/Include -I../include \\\n",
            "\ttrain_phase3_v1.cu \\\n",
            "\t../../phase3_gpu_optimized/src/kernels/im2col.cu ../../phase3_gpu_optimized/src/kernels/gemm.cu ../../phase3_gpu_optimized/src/kernels/relu.cu ../../phase3_gpu_optimized/src/kernels/maxpool.cu ../../phase3_gpu_optimized/src/kernels/upsample.cu \\\n",
            "\t../src/kernels/conv2d_backward.cu ../src/kernels/relu_backward.cu ../src/kernels/maxpool_backward.cu ../src/kernels/upsample_backward.cu ../src/kernels/mse_loss.cu \\\n",
            "\t../src/sgd_optimizer.cu ../src/data_loader.cpp ../src/logger.cpp \\\n",
            "\t-o train_phase3_v1\n",
            "Build complete: train_phase3_v1\n"
          ]
        }
      ],
      "source": [
        "!make -f MAKEFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dWS8lpk46Sx5"
      },
      "outputs": [],
      "source": [
        "!mkdir -p logs\n",
        "!mkdir -p weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XJyUiVc6UeP",
        "outputId": "f4501c0e-0aa1-43f2-8a20-f17e5720b599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 3_1 Training (Im2Col + GEMM) =====\n",
            "[DataLoader] Loading CIFAR-10 TRAIN dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 5 batch file(s)...\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Batch size: 32, Num batches: 1563\n",
            "[2025-12-14 12:09:17] Training started: epochs=1, batch_size=32, lr=0.001000\n",
            "[INFO] Initializing weights with Xavier initialization (seed=42)...\n",
            "[INFO] Memory allocated, starting training...\n",
            "Training Epoch 1/1...\n",
            "  0% - Loss: 0.273835 - Time: 14s\n",
            "  5% - Loss: 0.265127 - Time: 29s\n",
            "  10% - Loss: 0.236090 - Time: 43s\n",
            "  15% - Loss: 0.236766 - Time: 57s\n",
            "  20% - Loss: 0.204394 - Time: 72s\n",
            "  25% - Loss: 0.166483 - Time: 86s\n",
            "  30% - Loss: 0.155813 - Time: 100s\n",
            "  35% - Loss: 0.132926 - Time: 115s\n",
            "  40% - Loss: 0.107884 - Time: 129s\n",
            "  45% - Loss: 0.100753 - Time: 143s\n",
            "  50% - Loss: 0.099007 - Time: 158s\n",
            "  55% - Loss: 0.073520 - Time: 172s\n",
            "  60% - Loss: 0.078422 - Time: 186s\n",
            "  65% - Loss: 0.063890 - Time: 201s\n",
            "  70% - Loss: 0.073360 - Time: 215s\n",
            "  75% - Loss: 0.065327 - Time: 229s\n",
            "  80% - Loss: 0.058244 - Time: 244s\n",
            "  85% - Loss: 0.057486 - Time: 258s\n",
            "  90% - Loss: 0.059618 - Time: 272s\n",
            "  95% - Loss: 0.055554 - Time: 287s\n",
            "Epoch 1 complete - Avg Loss: 0.133873 (Best: 0.133873) - Time: 287.82s\n",
            "\n",
            "[2025-12-14 12:14:05] Epoch   1 | Loss: 0.133873 | Time: 287.82s\n",
            "[INFO] Saved weights to weights/phase3_v1_epoch_1.bin\n",
            "\n",
            "[INFO] Training completed. Generating summary...\n",
            "[INFO] Generating sample reconstructed images...\n",
            "[WARNING] Exception generating sample images: Conv1: invalid argument\n",
            "[INFO] Continuing with summary anyway...\n",
            "[INFO] Sample image phase completed (success=0)\n",
            "\n",
            "========================================\n",
            "       TRAINING SUMMARY\n",
            "========================================\n",
            "\n",
            "--- Training Performance ---\n",
            "Total training time: 287.83 seconds\n",
            "Number of epochs completed: 1\n",
            "Average time per epoch: 287.82 seconds\n",
            "Final reconstruction loss: 0.133873\n",
            "\n",
            "--- Memory Usage ---\n",
            "GPU Memory Used: 124 MB / 15095 MB\n",
            "GPU Memory Usage: 0.8%\n",
            "\n",
            "--- Sample Images ---\n",
            "âœ— Sample image generation failed or was disabled\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "TRAINING SUMMARY\n",
            "========================================\n",
            "Total Training Time: 287.83 seconds\n",
            "Final Reconstruction Loss: 0.133873\n",
            "\n",
            "Training Time Per Epoch:\n",
            "  Epoch   1: 287.82 seconds\n",
            "\n",
            "GPU Memory Usage:\n",
            "  Used: 124 MB\n",
            "  Total: 15095 MB\n",
            "  Usage: 0.82%\n",
            "\n",
            "Sample Reconstructed Images:\n",
            "  (Check logs directory for sample_original_*.ppm and sample_reconstructed_*.ppm files)\n",
            "========================================\n",
            "\n",
            "[2025-12-14 12:14:05] Training completed\n",
            "===== Training Complete =====\n"
          ]
        }
      ],
      "source": [
        "!./train_phase3_v1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNhNmfvH6Vkt",
        "outputId": "d1d88d24-e514-46d6-b026-b645f3db02c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Phase 3.1 Inference...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase3_gpu_optimized/Include -I../include infer_phase3_v1.cu ../../phase3_gpu_optimized/src/kernels/conv2d.cu ../../phase3_gpu_optimized/src/kernels/relu.cu ../../phase3_gpu_optimized/src/kernels/maxpool.cu ../../phase3_gpu_optimized/src/kernels/upsample.cu ../src/kernels/mse_loss.cu ../src/data_loader.cpp -o infer_phase3_v1\n",
            "Build complete: infer_phase3_v1\n"
          ]
        }
      ],
      "source": [
        "!make -f Makefile.infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIMI3EI86WsM",
        "outputId": "78fab294-9732-4434-b57d-3e76a53e81da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 3.1 Inference =====\n",
            "[INFO] Loading weights from: weights/phase3_v1_epoch_5.bin\n",
            "[ERROR] Could not open weight file: weights/phase3_v1_epoch_5.bin\n"
          ]
        }
      ],
      "source": [
        "!./infer_phase3_v1 weights/phase3_v1_epoch_5.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ePnqgJk6XgH",
        "outputId": "3591c2e4-eb3b-463e-9596-f070103593f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Feature Extraction...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase3_gpu_optimized/Include -I../include extract_features.cu ../../phase3_gpu_optimized/src/kernels/conv2d.cu ../../phase3_gpu_optimized/src/kernels/relu.cu ../../phase3_gpu_optimized/src/kernels/maxpool.cu ../src/data_loader.cpp -o extract_features\n",
            "Build complete: extract_features\n"
          ]
        }
      ],
      "source": [
        "!make -f Makefile.extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFnYKvvb6Yry",
        "outputId": "8ec4138c-60df-4bbe-d33f-1075ce37a0ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 2 Feature Extraction =====\n",
            "[INFO] Loading weights from: weights/phase3_v1_epoch_5.bin\n",
            "[ERROR] Could not open weight file: weights/phase3_v1_epoch_5.bin\n"
          ]
        }
      ],
      "source": [
        "!./extract_features weights/phase3_v1_epoch_5.bin features.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtoQYjr1FiT8"
      },
      "source": [
        "## Phase 3 - Version 2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvvqtFX4bTuT",
        "outputId": "0bbcfd5b-a00e-4ee9-905f-31d957c75dd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Parallel-Programming/train/P3_2\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Parallel-Programming/train/P3_2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4u27a61G9Q9",
        "outputId": "73239542-b114-485b-8224-bf009ad80bc9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Phase 3_2 Training (Kernel Fusion + Batching)...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase3_gpu_optimized_v2/Include -I../include \\\n",
            "\ttrain_phase3_v2.cu \\\n",
            "\t../../phase3_gpu_optimized_v2/src/kernels/im2col.cu ../../phase3_gpu_optimized_v2/src/kernels/gemm.cu ../../phase3_gpu_optimized_v2/src/kernels/relu.cu ../../phase3_gpu_optimized_v2/src/kernels/maxpool.cu ../../phase3_gpu_optimized_v2/src/kernels/upsample.cu \\\n",
            "\t../src/kernels/conv2d_backward.cu ../src/kernels/relu_backward.cu ../src/kernels/maxpool_backward.cu ../src/kernels/upsample_backward.cu ../src/kernels/mse_loss.cu \\\n",
            "\t../src/sgd_optimizer.cu ../src/data_loader.cpp ../src/logger.cpp \\\n",
            "\t-o train_phase3_v2\n",
            "Build complete: train_phase3_v2\n"
          ]
        }
      ],
      "source": [
        "!make -f MAKEFILE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "MaoKEFCRH6XU"
      },
      "outputs": [],
      "source": [
        "!mkdir -p logs\n",
        "!mkdir -p weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Sxsww1HGF0",
        "outputId": "79ac3299-a6fd-4bab-8531-779299dd8d68"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 3_2 Training (Im2Col + GEMM) =====\n",
            "[DataLoader] Loading CIFAR-10 TRAIN dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 5 batch file(s)...\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Batch size: 32, Num batches: 1563\n",
            "[2025-12-14 12:14:29] Training started: epochs=20, batch_size=32, lr=0.001000\n",
            "[INFO] Initializing weights with Xavier initialization (seed=42)...\n",
            "[INFO] Memory allocated (using memory pool pattern), starting training...\n",
            "Training Epoch 1/20...\n",
            "  0% - Loss: 0.257584 - Time: 14s\n",
            "  5% - Loss: 0.266229 - Time: 29s\n",
            "  10% - Loss: 0.225741 - Time: 45s\n",
            "  15% - Loss: 0.208582 - Time: 60s\n",
            "  20% - Loss: 0.194309 - Time: 75s\n",
            "  25% - Loss: 0.180611 - Time: 89s\n",
            "  30% - Loss: 0.145100 - Time: 104s\n",
            "  35% - Loss: 0.137308 - Time: 119s\n",
            "  40% - Loss: 0.145005 - Time: 134s\n",
            "  45% - Loss: 0.097126 - Time: 149s\n",
            "  50% - Loss: 0.090041 - Time: 164s\n",
            "  55% - Loss: 0.084297 - Time: 179s\n",
            "  60% - Loss: 0.077759 - Time: 194s\n",
            "  65% - Loss: 0.071787 - Time: 209s\n",
            "  70% - Loss: 0.069314 - Time: 224s\n",
            "  75% - Loss: 0.074356 - Time: 239s\n",
            "  80% - Loss: 0.058040 - Time: 254s\n",
            "  85% - Loss: 0.062379 - Time: 269s\n",
            "  90% - Loss: 0.055355 - Time: 284s\n",
            "  95% - Loss: 0.058025 - Time: 299s\n",
            "Epoch 1 complete - Avg Loss: 0.134111 (Best: 0.134111) - Time: 300.27s\n",
            "\n",
            "[2025-12-14 12:19:29] Epoch   1 | Loss: 0.134111 | Time: 300.27s\n",
            "[INFO] Saved weights to weights/phase3_v2_epoch_1.bin\n",
            "Training Epoch 2/20...\n",
            "  0% - Loss: 0.058151 - Time: 14s\n",
            "  5% - Loss: 0.060618 - Time: 29s\n",
            "  10% - Loss: 0.062643 - Time: 44s\n",
            "  15% - Loss: 0.054218 - Time: 60s\n",
            "  20% - Loss: 0.053857 - Time: 74s\n",
            "  25% - Loss: 0.058628 - Time: 89s\n",
            "  30% - Loss: 0.068817 - Time: 104s\n",
            "  35% - Loss: 0.061420 - Time: 119s\n",
            "  40% - Loss: 0.053621 - Time: 134s\n",
            "  45% - Loss: 0.065461 - Time: 149s\n",
            "  50% - Loss: 0.058662 - Time: 164s\n",
            "  55% - Loss: 0.063893 - Time: 179s\n",
            "  60% - Loss: 0.056800 - Time: 194s\n",
            "  65% - Loss: 0.053590 - Time: 209s\n",
            "  70% - Loss: 0.050638 - Time: 224s\n",
            "  75% - Loss: 0.059331 - Time: 239s\n",
            "  80% - Loss: 0.057919 - Time: 254s\n",
            "  85% - Loss: 0.060394 - Time: 269s\n",
            "  90% - Loss: 0.049370 - Time: 284s\n",
            "  95% - Loss: 0.052434 - Time: 299s\n",
            "Epoch 2 complete - Avg Loss: 0.057373 (Best: 0.057373) - Time: 300.31s\n",
            "\n",
            "[2025-12-14 12:24:30] Epoch   2 | Loss: 0.057373 | Time: 300.31s\n",
            "[INFO] Saved weights to weights/phase3_v2_epoch_2.bin\n",
            "Training Epoch 3/20...\n",
            "  0% - Loss: 0.051460 - Time: 14s\n",
            "  5% - Loss: 0.051923 - Time: 29s\n",
            "  10% - Loss: 0.059853 - Time: 44s\n",
            "  15% - Loss: 0.059864 - Time: 59s\n",
            "  20% - Loss: 0.052874 - Time: 74s\n",
            "  25% - Loss: 0.060533 - Time: 89s\n",
            "  30% - Loss: 0.052336 - Time: 104s\n",
            "  35% - Loss: 0.050241 - Time: 119s\n",
            "  40% - Loss: 0.054774 - Time: 134s\n",
            "  45% - Loss: 0.054878 - Time: 149s\n",
            "  50% - Loss: 0.053418 - Time: 164s\n",
            "  55% - Loss: 0.050929 - Time: 179s\n",
            "  60% - Loss: 0.048101 - Time: 194s\n",
            "  65% - Loss: 0.060705 - Time: 209s\n",
            "  70% - Loss: 0.058179 - Time: 224s\n",
            "  75% - Loss: 0.059920 - Time: 239s\n",
            "  80% - Loss: 0.043507 - Time: 254s\n",
            "  85% - Loss: 0.051631 - Time: 269s\n",
            "  90% - Loss: 0.047537 - Time: 284s\n",
            "  95% - Loss: 0.057822 - Time: 299s\n",
            "Epoch 3 complete - Avg Loss: 0.053890 (Best: 0.053890) - Time: 299.99s\n",
            "\n",
            "[2025-12-14 12:29:29] Epoch   3 | Loss: 0.053890 | Time: 299.99s\n",
            "[INFO] Saved weights to weights/phase3_v2_epoch_3.bin\n",
            "Training Epoch 4/20...\n",
            "  0% - Loss: 0.049275 - Time: 14s\n",
            "  5% - Loss: 0.046720 - Time: 29s\n",
            "  10% - Loss: 0.048422 - Time: 44s\n",
            "  15% - Loss: 0.058632 - Time: 59s\n",
            "  20% - Loss: 0.056149 - Time: 74s\n",
            "  25% - Loss: 0.044308 - Time: 89s\n",
            "  30% - Loss: 0.050052 - Time: 104s\n",
            "  35% - Loss: 0.045789 - Time: 119s\n",
            "  40% - Loss: 0.059562 - Time: 134s\n",
            "  45% - Loss: 0.058003 - Time: 149s\n",
            "  50% - Loss: 0.056248 - Time: 164s\n",
            "  55% - Loss: 0.048845 - Time: 179s\n",
            "  60% - Loss: 0.047784 - Time: 194s\n",
            "  65% - Loss: 0.051488 - Time: 209s\n",
            "  70% - Loss: 0.051601 - Time: 224s\n",
            "  75% - Loss: 0.055259 - Time: 239s\n",
            "  80% - Loss: 0.050216 - Time: 254s\n",
            "  85% - Loss: 0.052828 - Time: 269s\n",
            "  90% - Loss: 0.043117 - Time: 284s\n",
            "  95% - Loss: 0.061263 - Time: 299s\n",
            "Epoch 4 complete - Avg Loss: 0.051873 (Best: 0.051873) - Time: 300.36s\n",
            "\n",
            "[2025-12-14 12:34:30] Epoch   4 | Loss: 0.051873 | Time: 300.36s\n",
            "[INFO] Saved weights to weights/phase3_v2_epoch_4.bin\n",
            "Training Epoch 5/20...\n",
            "  0% - Loss: 0.051393 - Time: 15s\n",
            "  5% - Loss: 0.057596 - Time: 30s\n",
            "  10% - Loss: 0.052212 - Time: 45s\n",
            "  15% - Loss: 0.052821 - Time: 60s\n",
            "  20% - Loss: 0.050401 - Time: 75s\n",
            "  25% - Loss: 0.056798 - Time: 90s\n",
            "  30% - Loss: 0.055980 - Time: 104s\n",
            "  35% - Loss: 0.054408 - Time: 119s\n",
            "  40% - Loss: 0.048847 - Time: 134s\n",
            "  45% - Loss: 0.056876 - Time: 149s\n",
            "  50% - Loss: 0.052564 - Time: 164s\n",
            "  55% - Loss: 0.045798 - Time: 179s\n",
            "  60% - Loss: 0.044472 - Time: 194s\n",
            "  65% - Loss: 0.047883 - Time: 209s\n",
            "  70% - Loss: 0.063677 - Time: 224s\n",
            "  75% - Loss: 0.044123 - Time: 239s\n",
            "  80% - Loss: 0.044109 - Time: 254s\n",
            "  85% - Loss: 0.048997 - Time: 269s\n",
            "  90% - Loss: 0.051089 - Time: 284s\n",
            "  95% - Loss: 0.051620 - Time: 299s\n",
            "Epoch 5 complete - Avg Loss: 0.051467 (Best: 0.051467) - Time: 300.28s\n",
            "\n",
            "[2025-12-14 12:39:30] Epoch   5 | Loss: 0.051467 | Time: 300.28s\n",
            "[INFO] Saved weights to weights/phase3_v2_epoch_5.bin\n",
            "Training Epoch 6/20...\n",
            "  0% - Loss: 0.056899 - Time: 14s\n",
            "  5% - Loss: 0.055557 - Time: 29s\n",
            "  10% - Loss: 0.056643 - Time: 44s\n",
            "  15% - Loss: 0.051224 - Time: 59s\n",
            "  20% - Loss: 0.051060 - Time: 74s\n",
            "  25% - Loss: 0.053992 - Time: 89s\n",
            "  30% - Loss: 0.051586 - Time: 104s\n",
            "  35% - Loss: 0.048606 - Time: 119s\n",
            "  40% - Loss: 0.055267 - Time: 134s\n",
            "  45% - Loss: 0.059618 - Time: 149s\n",
            "  50% - Loss: 0.051669 - Time: 164s\n",
            "  55% - Loss: 0.047417 - Time: 179s\n",
            "  60% - Loss: 0.055046 - Time: 194s\n",
            "  65% - Loss: 0.053579 - Time: 209s\n",
            "  70% - Loss: 0.061422 - Time: 224s\n",
            "  75% - Loss: 0.056239 - Time: 239s\n",
            "  80% - Loss: 0.052604 - Time: 254s\n",
            "  85% - Loss: 0.048322 - Time: 269s\n",
            "  90% - Loss: 0.055529 - Time: 284s\n",
            "  95% - Loss: 0.052450 - Time: 299s\n",
            "Epoch 6 complete - Avg Loss: 0.052590 (Best: 0.051467, No improvement: 1/3) - Time: 300.01s\n",
            "\n",
            "[2025-12-14 12:44:30] Epoch   6 | Loss: 0.052590 | Time: 300.01s\n",
            "[INFO] Saved weights to weights/phase3_v2_epoch_6.bin\n",
            "Training Epoch 7/20...\n",
            "  0% - Loss: 0.051057 - Time: 14s\n",
            "  5% - Loss: 0.051296 - Time: 29s\n",
            "  10% - Loss: 0.056783 - Time: 44s\n",
            "  15% - Loss: 0.062553 - Time: 59s\n",
            "  20% - Loss: 0.053822 - Time: 74s\n",
            "  25% - Loss: 0.061267 - Time: 89s\n",
            "  30% - Loss: 0.057750 - Time: 104s\n",
            "  35% - Loss: 0.054673 - Time: 119s\n",
            "  40% - Loss: 0.063936 - Time: 134s\n",
            "  45% - Loss: 0.048171 - Time: 149s\n",
            "  50% - Loss: 0.052500 - Time: 164s\n",
            "  55% - Loss: 0.064524 - Time: 179s\n",
            "  60% - Loss: 0.064588 - Time: 194s\n",
            "  65% - Loss: 0.052027 - Time: 209s\n",
            "  70% - Loss: 0.055008 - Time: 224s\n",
            "  75% - Loss: 0.057069 - Time: 239s\n",
            "  80% - Loss: 0.062611 - Time: 254s\n",
            "  85% - Loss: 0.064953 - Time: 269s\n",
            "  90% - Loss: 0.061206 - Time: 284s\n",
            "  95% - Loss: 0.049254 - Time: 299s\n",
            "Epoch 7 complete - Avg Loss: 0.055001 (Best: 0.051467, No improvement: 2/3) - Time: 300.27s\n",
            "\n",
            "[2025-12-14 12:49:30] Epoch   7 | Loss: 0.055001 | Time: 300.27s\n",
            "[INFO] Saved weights to weights/phase3_v2_epoch_7.bin\n",
            "Training Epoch 8/20...\n",
            "  0% - Loss: 0.052702 - Time: 15s\n",
            "  5% - Loss: 0.058711 - Time: 30s\n",
            "  10% - Loss: 0.049599 - Time: 44s\n",
            "  15% - Loss: 0.058145 - Time: 59s\n",
            "  20% - Loss: 0.063459 - Time: 75s\n",
            "  25% - Loss: 0.046899 - Time: 90s\n",
            "  30% - Loss: 0.057334 - Time: 105s\n",
            "  35% - Loss: 0.059621 - Time: 119s\n",
            "  40% - Loss: 0.053655 - Time: 134s\n",
            "  45% - Loss: 0.057579 - Time: 149s\n",
            "  50% - Loss: 0.068809 - Time: 164s\n",
            "  55% - Loss: 0.058334 - Time: 179s\n",
            "  60% - Loss: 0.057053 - Time: 194s\n",
            "  65% - Loss: 0.050151 - Time: 209s\n",
            "  70% - Loss: 0.056807 - Time: 224s\n",
            "  75% - Loss: 0.059679 - Time: 239s\n",
            "  80% - Loss: 0.058274 - Time: 254s\n",
            "  85% - Loss: 0.050812 - Time: 269s\n",
            "  90% - Loss: 0.053477 - Time: 284s\n",
            "  95% - Loss: 0.061011 - Time: 299s\n",
            "Epoch 8 complete - Avg Loss: 0.058206 (Best: 0.051467, No improvement: 3/3) - Time: 300.29s\n",
            "\n",
            "[INFO] Early stopping triggered! No improvement for 3 epochs.\n",
            "[INFO] Best loss: 0.051467 at epoch 5\n",
            "\n",
            "[INFO] Training stopped early. Generating summary...\n",
            "[INFO] Generating sample reconstructed images...\n",
            "[WARNING] CUDA error during forward pass: invalid argument\n",
            "\n",
            "========================================\n",
            "       TRAINING SUMMARY\n",
            "========================================\n",
            "\n",
            "[EARLY STOP] Training stopped after epoch 8 (no improvement for 3 epochs)\n",
            "\n",
            "--- Training Performance ---\n",
            "Total training time: 2401.81 seconds\n",
            "Number of epochs completed: 8\n",
            "Average time per epoch: 300.22 seconds\n",
            "\n",
            "Training Time Per Epoch:\n",
            "  Epoch   1: 300.27 seconds\n",
            "  Epoch   2: 300.31 seconds\n",
            "  Epoch   3: 299.99 seconds\n",
            "  Epoch   4: 300.36 seconds\n",
            "  Epoch   5: 300.28 seconds\n",
            "  Epoch   6: 300.01 seconds\n",
            "  Epoch   7: 300.27 seconds\n",
            "  Epoch   8: 300.29 seconds\n",
            "Final reconstruction loss: 0.051467\n",
            "\n",
            "--- Memory Usage ---\n",
            "GPU Memory Used: 490 MB / 15095 MB\n",
            "GPU Memory Usage: 3.2%\n",
            "\n",
            "--- Sample Images ---\n",
            "âœ— Sample image generation failed or was disabled\n",
            "========================================\n",
            "\n",
            "\n",
            "========================================\n",
            "TRAINING SUMMARY\n",
            "========================================\n",
            "Total Training Time: 2401.81 seconds\n",
            "Final Reconstruction Loss: 0.051467\n",
            "\n",
            "Training Time Per Epoch:\n",
            "  Epoch   1: 300.27 seconds\n",
            "  Epoch   2: 300.31 seconds\n",
            "  Epoch   3: 299.99 seconds\n",
            "  Epoch   4: 300.36 seconds\n",
            "  Epoch   5: 300.28 seconds\n",
            "  Epoch   6: 300.01 seconds\n",
            "  Epoch   7: 300.27 seconds\n",
            "  Epoch   8: 300.29 seconds\n",
            "\n",
            "GPU Memory Usage:\n",
            "  Used: 490 MB\n",
            "  Total: 15095 MB\n",
            "  Usage: 3.25%\n",
            "\n",
            "Sample Reconstructed Images:\n",
            "  (Check logs directory for sample_original_*.ppm and sample_reconstructed_*.ppm files)\n",
            "========================================\n",
            "\n",
            "[2025-12-14 12:54:31] Training completed\n",
            "===== Training Complete =====\n"
          ]
        }
      ],
      "source": [
        "!./train_phase3_v2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AtF7ZVtMKTX4",
        "outputId": "5c1305d4-4538-44b9-acbd-9fc70164fde9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Phase 3.2 Inference...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase3_gpu_optimized_v2/Include -I../include infer_phase3_v2.cu ../../phase3_gpu_optimized_v2/src/kernels/conv2d.cu ../../phase3_gpu_optimized_v2/src/kernels/relu.cu ../../phase3_gpu_optimized_v2/src/kernels/maxpool.cu ../../phase3_gpu_optimized_v2/src/kernels/upsample.cu ../src/kernels/mse_loss.cu ../src/data_loader.cpp -o infer_phase3_v2\n",
            "Build complete: infer_phase3_v2\n"
          ]
        }
      ],
      "source": [
        "!make -f Makefile.infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0SMO6RZKdpd",
        "outputId": "c5699489-7464-4dbe-c137-61d7a712cab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 3.2 Inference =====\n",
            "[INFO] Loading weights from: weights/phase3_v2_epoch_5.bin\n",
            "[INFO] Loaded weights successfully\n",
            "[DataLoader] Loading CIFAR-10 TEST dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 1 batch file(s)...\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Batch size: 32, Num batches: 313\n",
            "[INFO] Running inference on 10000 test images...\n",
            "[INFO] Displaying first 10 results...\n",
            "\n",
            "Image 1/10000 - Reconstruction Loss: 0.0408031\n",
            "Image 2/10000 - Reconstruction Loss: 0.0726685\n",
            "Image 3/10000 - Reconstruction Loss: 0.0531367\n",
            "Image 4/10000 - Reconstruction Loss: 0.0553178\n",
            "Image 5/10000 - Reconstruction Loss: 0.0222059\n",
            "Image 6/10000 - Reconstruction Loss: 0.0283713\n",
            "Image 7/10000 - Reconstruction Loss: 0.0538789\n",
            "Image 8/10000 - Reconstruction Loss: 0.0229589\n",
            "Image 9/10000 - Reconstruction Loss: 0.0423939\n",
            "Image 10/10000 - Reconstruction Loss: 0.0849719\n",
            "Processed 4000/10000 images...\n",
            "Processed 8000/10000 images...\n",
            "Processed 10000/10000 images...\n",
            "\n",
            "[RESULT] Tested on 10000 images\n",
            "[RESULT] Average Reconstruction Loss: 0.0520317\n",
            "===== Inference Complete =====\n"
          ]
        }
      ],
      "source": [
        "!./infer_phase3_v2 weights/phase3_v2_epoch_5.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzM5MQjULET9",
        "outputId": "eddfe427-f0b6-4494-ff66-59e6b0942b4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compiling Feature Extraction...\n",
            "nvcc -std=c++11 -arch=sm_75 -O3 -I../../phase3_gpu_optimized_v2/Include -I../include extract_features.cu ../../phase3_gpu_optimized_v2/src/kernels/conv2d.cu ../../phase3_gpu_optimized_v2/src/kernels/relu.cu ../../phase3_gpu_optimized_v2/src/kernels/maxpool.cu ../src/data_loader.cpp -o extract_features\n",
            "Build complete: extract_features\n"
          ]
        }
      ],
      "source": [
        "!make -f Makefile.extract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QXVVyk2cLo1P",
        "outputId": "ff45f514-fa52-4c9f-dbb3-e9fc1b3658e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "===== Phase 2 Feature Extraction =====\n",
            "[INFO] Loading weights from: weights/phase3_v2_epoch_5.bin\n",
            "[INFO] Loaded encoder weights\n",
            "[INFO] Extracting features from 60k images...\n",
            "[INFO] Output format: Label (1 byte) + Features (8192 floats)\n",
            "[DataLoader] Loading CIFAR-10 TRAIN dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 5 batch file(s)...\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Loaded 50000 images\n",
            "[DataLoader] Batch size: 100, Num batches: 500\n",
            "\n",
            "[TRAIN] Processing 50000 training images...\n",
            "  Processed: 1000 images\n",
            "  Processed: 2000 images\n",
            "  Processed: 3000 images\n",
            "  Processed: 4000 images\n",
            "  Processed: 5000 images\n",
            "  Processed: 6000 images\n",
            "  Processed: 7000 images\n",
            "  Processed: 8000 images\n",
            "  Processed: 9000 images\n",
            "  Processed: 10000 images\n",
            "  Processed: 11000 images\n",
            "  Processed: 12000 images\n",
            "  Processed: 13000 images\n",
            "  Processed: 14000 images\n",
            "  Processed: 15000 images\n",
            "  Processed: 16000 images\n",
            "  Processed: 17000 images\n",
            "  Processed: 18000 images\n",
            "  Processed: 19000 images\n",
            "  Processed: 20000 images\n",
            "  Processed: 21000 images\n",
            "  Processed: 22000 images\n",
            "  Processed: 23000 images\n",
            "  Processed: 24000 images\n",
            "  Processed: 25000 images\n",
            "  Processed: 26000 images\n",
            "  Processed: 27000 images\n",
            "  Processed: 28000 images\n",
            "  Processed: 29000 images\n",
            "  Processed: 30000 images\n",
            "  Processed: 31000 images\n",
            "  Processed: 32000 images\n",
            "  Processed: 33000 images\n",
            "  Processed: 34000 images\n",
            "  Processed: 35000 images\n",
            "  Processed: 36000 images\n",
            "  Processed: 37000 images\n",
            "  Processed: 38000 images\n",
            "  Processed: 39000 images\n",
            "  Processed: 40000 images\n",
            "  Processed: 41000 images\n",
            "  Processed: 42000 images\n",
            "  Processed: 43000 images\n",
            "  Processed: 44000 images\n",
            "  Processed: 45000 images\n",
            "  Processed: 46000 images\n",
            "  Processed: 47000 images\n",
            "  Processed: 48000 images\n",
            "  Processed: 49000 images\n",
            "  Processed: 50000 images\n",
            "[DataLoader] Loading CIFAR-10 TEST dataset from: ../../Data/cifar-10-batches-bin/\n",
            "[DataLoader] Loading 1 batch file(s)...\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Loaded 10000 images\n",
            "[DataLoader] Batch size: 100, Num batches: 100\n",
            "\n",
            "[TEST] Processing 10000 test images...\n",
            "  Processed: 51000 images\n",
            "  Processed: 52000 images\n",
            "  Processed: 53000 images\n",
            "  Processed: 54000 images\n",
            "  Processed: 55000 images\n",
            "  Processed: 56000 images\n",
            "  Processed: 57000 images\n",
            "  Processed: 58000 images\n",
            "  Processed: 59000 images\n",
            "  Processed: 60000 images\n",
            "\n",
            "[RESULT] Extracted features from 60000 images\n",
            "[INFO] Output saved to: features.bin\n",
            "[INFO] File size: 1875 MB\n",
            "[INFO] Format: Label (1 byte) + Features (8192 floats = 32768 bytes)\n",
            "===== Feature Extraction Complete =====\n"
          ]
        }
      ],
      "source": [
        "!./extract_features weights/phase3_v2_epoch_5.bin features.bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMnpkQaN5RAB"
      },
      "source": [
        "# Training SVM\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pfyfxIG5ZAc",
        "outputId": "8fcb78c8-9ca2-44c0-f803-e4ee61c68d7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/Parallel-Programming/phase4_svm_gpu\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Parallel-Programming/phase4_svm_gpu/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "fcBeqBDk-K3J"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install cuml-cu12 --extra-index-url=https://pypi.nvidia.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Visualization and Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "%pip install matplotlib pandas numpy -q\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import visualization script\n",
        "import sys\n",
        "sys.path.append('/content/Parallel-Programming')\n",
        "from visualize_training_results import *\n",
        "\n",
        "# Set up paths\n",
        "import os\n",
        "os.chdir('/content/Parallel-Programming')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Parse training logs and generate visualizations\n",
        "log_files = {\n",
        "    'P2': 'train/P2/logs/phase2_training.log',\n",
        "    'P3.1': 'train/P3_1/logs/phase3_v1_training.log',\n",
        "    'P3.2': 'train/P3_2/logs/phase3_v2_training.log'\n",
        "}\n",
        "\n",
        "parsers = {}\n",
        "for phase, log_path in log_files.items():\n",
        "    if os.path.exists(log_path):\n",
        "        parser = TrainingLogParser(log_path)\n",
        "        if parser.parse():\n",
        "            parsers[phase] = parser\n",
        "            print(f\"âœ“ Parsed {phase}: {parser.get_data()['num_epochs']} epochs\")\n",
        "        else:\n",
        "            print(f\"âœ— Failed to parse {phase}\")\n",
        "    else:\n",
        "        print(f\"âœ— Log file not found: {log_path}\")\n",
        "\n",
        "print(f\"\\nSuccessfully parsed {len(parsers)} log file(s)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loss Curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot loss curves\n",
        "if parsers:\n",
        "    plot_loss_curves(parsers)\n",
        "else:\n",
        "    print(\"No training data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Performance Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot performance comparison\n",
        "if parsers:\n",
        "    plot_performance_comparison(parsers)\n",
        "else:\n",
        "    print(\"No training data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inference Speed Comparison\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Inference times from benchmark results (60k images)\n",
        "inference_times = {\n",
        "    'P2': 10.97,    # From Cell 8 output\n",
        "    'P3.1': 1.57,   # From Cell 13 output\n",
        "    'P3.2': 0.64    # From Cell 18 output\n",
        "}\n",
        "\n",
        "plot_inference_comparison(inference_times)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comprehensive Summary Table\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create and display summary table\n",
        "if parsers:\n",
        "    df = create_summary_table(parsers, inference_times)\n",
        "    display(df)\n",
        "    \n",
        "    # Calculate additional metrics\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    print(\"KEY INSIGHTS\")\n",
        "    print(\"=\"*80)\n",
        "    \n",
        "    if 'P2' in parsers and 'P3.2' in parsers:\n",
        "        p2_data = parsers['P2'].get_data()\n",
        "        p32_data = parsers['P3.2'].get_data()\n",
        "        \n",
        "        print(f\"\\n1. Inference Speed:\")\n",
        "        print(f\"   - P3.2 is {inference_times['P2'] / inference_times['P3.2']:.1f}x faster than P2\")\n",
        "        print(f\"   - P3.1 is {inference_times['P2'] / inference_times['P3.1']:.1f}x faster than P2\")\n",
        "        \n",
        "        print(f\"\\n2. Training Efficiency:\")\n",
        "        if p2_data['num_epochs'] > 0 and p32_data['num_epochs'] > 0:\n",
        "            p2_avg = np.mean(p2_data['times'])\n",
        "            p32_avg = np.mean(p32_data['times'])\n",
        "            print(f\"   - P2 avg time/epoch: {p2_avg:.2f}s\")\n",
        "            print(f\"   - P3.2 avg time/epoch: {p32_avg:.2f}s\")\n",
        "            print(f\"   - P3.2 is {p2_avg/p32_avg:.2f}x slower per epoch (due to batching overhead)\")\n",
        "        \n",
        "        print(f\"\\n3. Model Quality:\")\n",
        "        print(f\"   - P2 final loss: {p2_data['final_loss']:.6f}\")\n",
        "        print(f\"   - P3.2 final loss: {p32_data['final_loss']:.6f}\")\n",
        "        if abs(p2_data['final_loss'] - p32_data['final_loss']) < 0.001:\n",
        "            print(f\"   - âœ“ Both phases achieve similar reconstruction quality\")\n",
        "        \n",
        "        print(f\"\\n4. Memory Usage:\")\n",
        "        print(f\"   - P2: {p2_data['memory_usage_percent']:.2f}%\")\n",
        "        print(f\"   - P3.2: {p32_data['memory_usage_percent']:.2f}%\")\n",
        "        \n",
        "        print(f\"\\n5. Early Stopping:\")\n",
        "        print(f\"   - P2: {'Yes' if p2_data['early_stopped'] else 'No'} (Best: Epoch {p2_data['best_epoch']})\")\n",
        "        print(f\"   - P3.2: {'Yes' if p32_data['early_stopped'] else 'No'} (Best: Epoch {p32_data['best_epoch']})\")\n",
        "else:\n",
        "    print(\"No training data available\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Epoch-by-Epoch Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create detailed epoch comparison\n",
        "if len(parsers) >= 2:\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    \n",
        "    # Get common epochs\n",
        "    all_epochs = set()\n",
        "    for parser in parsers.values():\n",
        "        all_epochs.update(parser.epochs)\n",
        "    common_epochs = sorted(list(all_epochs))\n",
        "    \n",
        "    # Plot 1: Loss progression\n",
        "    ax = axes[0, 0]\n",
        "    for phase, parser in parsers.items():\n",
        "        data = parser.get_data()\n",
        "        ax.plot(data['epochs'], data['losses'], \n",
        "               label=phase, marker='o', linewidth=2, markersize=6)\n",
        "    ax.set_xlabel('Epoch', fontweight='bold')\n",
        "    ax.set_ylabel('Loss', fontweight='bold')\n",
        "    ax.set_title('Loss Progression Comparison', fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_yscale('log')\n",
        "    \n",
        "    # Plot 2: Time per epoch\n",
        "    ax = axes[0, 1]\n",
        "    for phase, parser in parsers.items():\n",
        "        data = parser.get_data()\n",
        "        ax.plot(data['epochs'], data['times'], \n",
        "               label=phase, marker='s', linewidth=2, markersize=6)\n",
        "    ax.set_xlabel('Epoch', fontweight='bold')\n",
        "    ax.set_ylabel('Time (seconds)', fontweight='bold')\n",
        "    ax.set_title('Time per Epoch', fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 3: Cumulative time\n",
        "    ax = axes[1, 0]\n",
        "    for phase, parser in parsers.items():\n",
        "        data = parser.get_data()\n",
        "        cumulative = np.cumsum([0] + data['times'])\n",
        "        ax.plot([0] + data['epochs'], cumulative, \n",
        "               label=phase, marker='^', linewidth=2, markersize=6)\n",
        "    ax.set_xlabel('Epoch', fontweight='bold')\n",
        "    ax.set_ylabel('Cumulative Time (seconds)', fontweight='bold')\n",
        "    ax.set_title('Cumulative Training Time', fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Plot 4: Loss reduction rate\n",
        "    ax = axes[1, 1]\n",
        "    for phase, parser in parsers.items():\n",
        "        data = parser.get_data()\n",
        "        if len(data['losses']) > 1:\n",
        "            initial_loss = data['losses'][0]\n",
        "            reduction = [(initial_loss - loss) / initial_loss * 100 for loss in data['losses']]\n",
        "            ax.plot(data['epochs'], reduction, \n",
        "                   label=phase, marker='d', linewidth=2, markersize=6)\n",
        "    ax.set_xlabel('Epoch', fontweight='bold')\n",
        "    ax.set_ylabel('Loss Reduction (%)', fontweight='bold')\n",
        "    ax.set_title('Loss Reduction Percentage', fontweight='bold')\n",
        "    ax.legend()\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Need at least 2 phases for comparison\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NWQpF2sf-dYB",
        "outputId": "bd1698ec-b0e9-4dda-e42f-72512811d313"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[SYSTEM] ÄÃ£ tÃ¬m tháº¥y RAPIDS cuML. Sáºµn sÃ ng cháº¡y trÃªn GPU.\n",
            "[I/O] Äang Ä‘á»c file: /content/Parallel-Programming/train/P3_2/features.bin...\n",
            " -> ÄÃ£ Ä‘á»c 60000 máº«u trong 1.37s\n",
            "[PREPROCESS] Chuáº©n hÃ³a dá»¯ liá»‡u...\n",
            "[CUML] Training (Kernel: rbf, C: 10.0)...\n",
            "[2025-12-14 12:57:01.539] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:02.399] [CUML] [debug] SMO solver finished after 45 outer iterations, total inner 22480 iterations, and diff 0.000998\n",
            "[2025-12-14 12:57:04.212] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:04.860] [CUML] [debug] SMO solver finished after 51 outer iterations, total inner 28714 iterations, and diff 0.000995\n",
            "[2025-12-14 12:57:06.800] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:07.405] [CUML] [debug] SMO solver finished after 41 outer iterations, total inner 21225 iterations, and diff 0.000986\n",
            "[2025-12-14 12:57:08.977] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:09.541] [CUML] [debug] SMO solver finished after 42 outer iterations, total inner 23407 iterations, and diff 0.000990\n",
            "[2025-12-14 12:57:11.125] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:11.598] [CUML] [debug] SMO solver finished after 36 outer iterations, total inner 17598 iterations, and diff 0.000998\n",
            "[2025-12-14 12:57:13.224] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:13.613] [CUML] [debug] SMO solver finished after 29 outer iterations, total inner 13987 iterations, and diff 0.000981\n",
            "[2025-12-14 12:57:14.983] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:15.503] [CUML] [debug] SMO solver finished after 40 outer iterations, total inner 20098 iterations, and diff 0.000980\n",
            "[2025-12-14 12:57:16.928] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:17.716] [CUML] [debug] SMO solver finished after 62 outer iterations, total inner 36487 iterations, and diff 0.000969\n",
            "[2025-12-14 12:57:19.242] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:19.880] [CUML] [debug] SMO solver finished after 47 outer iterations, total inner 24587 iterations, and diff 0.000991\n",
            "[2025-12-14 12:57:21.542] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:22.008] [CUML] [debug] SMO solver finished after 33 outer iterations, total inner 15602 iterations, and diff 0.000988\n",
            "[2025-12-14 12:57:23.227] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:23.778] [CUML] [debug] SMO solver finished after 39 outer iterations, total inner 18255 iterations, and diff 0.000999\n",
            "[2025-12-14 12:57:25.144] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:25.570] [CUML] [debug] SMO solver finished after 30 outer iterations, total inner 14475 iterations, and diff 0.000996\n",
            "[2025-12-14 12:57:26.762] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:27.235] [CUML] [debug] SMO solver finished after 34 outer iterations, total inner 15683 iterations, and diff 0.000990\n",
            "[2025-12-14 12:57:28.794] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:29.227] [CUML] [debug] SMO solver finished after 31 outer iterations, total inner 14283 iterations, and diff 0.000992\n",
            "[2025-12-14 12:57:30.646] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:31.169] [CUML] [debug] SMO solver finished after 37 outer iterations, total inner 17010 iterations, and diff 0.000994\n",
            "[2025-12-14 12:57:33.412] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:34.117] [CUML] [debug] SMO solver finished after 45 outer iterations, total inner 22692 iterations, and diff 0.000997\n",
            "[2025-12-14 12:57:37.243] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:38.308] [CUML] [debug] SMO solver finished after 74 outer iterations, total inner 36768 iterations, and diff 0.000991\n",
            "[2025-12-14 12:57:40.488] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:41.565] [CUML] [debug] SMO solver finished after 79 outer iterations, total inner 43961 iterations, and diff 0.000997\n",
            "[2025-12-14 12:57:43.431] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:44.484] [CUML] [debug] SMO solver finished after 85 outer iterations, total inner 51402 iterations, and diff 0.000994\n",
            "[2025-12-14 12:57:46.198] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:47.158] [CUML] [debug] SMO solver finished after 76 outer iterations, total inner 41745 iterations, and diff 0.000996\n",
            "[2025-12-14 12:57:49.091] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:49.882] [CUML] [debug] SMO solver finished after 59 outer iterations, total inner 34306 iterations, and diff 0.000986\n",
            "[2025-12-14 12:57:51.040] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:51.812] [CUML] [debug] SMO solver finished after 59 outer iterations, total inner 32833 iterations, and diff 0.000996\n",
            "[2025-12-14 12:57:52.968] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:53.439] [CUML] [debug] SMO solver finished after 36 outer iterations, total inner 18517 iterations, and diff 0.000966\n",
            "[2025-12-14 12:57:54.608] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:55.106] [CUML] [debug] SMO solver finished after 36 outer iterations, total inner 17380 iterations, and diff 0.001000\n",
            "[2025-12-14 12:57:56.289] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:57.189] [CUML] [debug] SMO solver finished after 69 outer iterations, total inner 39892 iterations, and diff 0.000990\n",
            "[2025-12-14 12:57:58.345] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:57:59.595] [CUML] [debug] SMO solver finished after 98 outer iterations, total inner 53776 iterations, and diff 0.000980\n",
            "[2025-12-14 12:58:01.651] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:02.596] [CUML] [debug] SMO solver finished after 68 outer iterations, total inner 37437 iterations, and diff 0.000958\n",
            "[2025-12-14 12:58:05.022] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:05.931] [CUML] [debug] SMO solver finished after 63 outer iterations, total inner 32624 iterations, and diff 0.000997\n",
            "[2025-12-14 12:58:08.466] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:09.001] [CUML] [debug] SMO solver finished after 34 outer iterations, total inner 17285 iterations, and diff 0.000998\n",
            "[2025-12-14 12:58:11.620] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:12.304] [CUML] [debug] SMO solver finished after 42 outer iterations, total inner 20373 iterations, and diff 0.000984\n",
            "[2025-12-14 12:58:14.630] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:15.590] [CUML] [debug] SMO solver finished after 68 outer iterations, total inner 37903 iterations, and diff 0.000996\n",
            "[2025-12-14 12:58:17.319] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:18.128] [CUML] [debug] SMO solver finished after 61 outer iterations, total inner 36479 iterations, and diff 0.000986\n",
            "[2025-12-14 12:58:19.304] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:20.163] [CUML] [debug] SMO solver finished after 65 outer iterations, total inner 37573 iterations, and diff 0.000978\n",
            "[2025-12-14 12:58:21.316] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:21.745] [CUML] [debug] SMO solver finished after 31 outer iterations, total inner 15788 iterations, and diff 0.000974\n",
            "[2025-12-14 12:58:22.893] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:23.347] [CUML] [debug] SMO solver finished after 32 outer iterations, total inner 15749 iterations, and diff 0.000995\n",
            "[2025-12-14 12:58:24.669] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:25.388] [CUML] [debug] SMO solver finished after 53 outer iterations, total inner 28916 iterations, and diff 0.000983\n",
            "[2025-12-14 12:58:26.701] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:27.579] [CUML] [debug] SMO solver finished after 66 outer iterations, total inner 34825 iterations, and diff 0.000990\n",
            "[2025-12-14 12:58:29.469] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:29.872] [CUML] [debug] SMO solver finished after 29 outer iterations, total inner 13926 iterations, and diff 0.000955\n",
            "[2025-12-14 12:58:33.115] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:33.693] [CUML] [debug] SMO solver finished after 35 outer iterations, total inner 16559 iterations, and diff 0.000993\n",
            "[2025-12-14 12:58:36.863] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:37.491] [CUML] [debug] SMO solver finished after 42 outer iterations, total inner 21005 iterations, and diff 0.000980\n",
            "[2025-12-14 12:58:40.088] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:40.474] [CUML] [debug] SMO solver finished after 25 outer iterations, total inner 11556 iterations, and diff 0.000986\n",
            "[2025-12-14 12:58:42.437] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:42.957] [CUML] [debug] SMO solver finished after 32 outer iterations, total inner 14755 iterations, and diff 0.000997\n",
            "[2025-12-14 12:58:44.679] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:45.089] [CUML] [debug] SMO solver finished after 29 outer iterations, total inner 13513 iterations, and diff 0.000985\n",
            "[2025-12-14 12:58:46.296] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:46.913] [CUML] [debug] SMO solver finished after 44 outer iterations, total inner 20955 iterations, and diff 0.000982\n",
            "[2025-12-14 12:58:48.071] [CUML] [debug] Creating working set with 1024 elements\n",
            "[2025-12-14 12:58:48.713] [CUML] [debug] SMO solver finished after 46 outer iterations, total inner 23433 iterations, and diff 0.000988\n",
            "[DONE] Train time: 118.97s\n",
            "[EVAL] Predicting...\n",
            " -> Eval time: 27.20s\n",
            " -> Accuracy: 67.41%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.72      0.71      0.72      1000\n",
            "  automobile       0.76      0.79      0.77      1000\n",
            "        bird       0.60      0.53      0.56      1000\n",
            "         cat       0.45      0.54      0.49      1000\n",
            "        deer       0.63      0.62      0.63      1000\n",
            "         dog       0.59      0.58      0.58      1000\n",
            "        frog       0.75      0.75      0.75      1000\n",
            "       horse       0.76      0.71      0.73      1000\n",
            "        ship       0.79      0.77      0.78      1000\n",
            "       truck       0.73      0.73      0.73      1000\n",
            "\n",
            "    accuracy                           0.67     10000\n",
            "   macro avg       0.68      0.67      0.68     10000\n",
            "weighted avg       0.68      0.67      0.68     10000\n",
            "\n",
            "[PLOT] Saved matrix to ./output_cuml\n"
          ]
        }
      ],
      "source": [
        "!python svm_classifier.py --input_file /content/Parallel-Programming/train/P3_2/features.bin"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
